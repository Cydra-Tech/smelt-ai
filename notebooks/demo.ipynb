{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Smelt — Live Demo\n",
    "\n",
    "Interactive walkthrough of smelt across **OpenAI**, **Anthropic**, and **Google Gemini**.\n",
    "\n",
    "Tests:\n",
    "1. Basic classification (all 3 providers)\n",
    "2. Sentiment analysis with score validation\n",
    "3. Support ticket triage (complex schema)\n",
    "4. Parameter tuning (temperature, top_p)\n",
    "5. Batch configuration (batch_size, concurrency)\n",
    "6. Error handling (stop_on_exhaustion)\n",
    "7. Async execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI key:    set\n",
      "Anthropic key: set\n",
      "Gemini key:    set\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Literal\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from smelt import Model, Job, SmeltResult, SmeltMetrics, BatchError\n",
    "from smelt.errors import SmeltExhaustionError\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "ANTHROPIC_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "GEMINI_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "print(f\"OpenAI key:    {'set' if OPENAI_KEY else 'MISSING'}\")\n",
    "print(f\"Anthropic key: {'set' if ANTHROPIC_KEY else 'MISSING'}\")\n",
    "print(f\"Gemini key:    {'set' if GEMINI_KEY else 'MISSING'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-header",
   "metadata": {},
   "source": [
    "## Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "load-data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Companies: 10 rows\n",
      "Products:  10 rows\n",
      "Tickets:   10 rows\n",
      "\n",
      "Sample company: {'name': 'Apple Inc.', 'description': 'Designs and manufactures consumer electronics and software', 'founded': '1976', 'headquarters': 'Cupertino CA', 'employees': '164000'}\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = Path(\"../tests/data\")\n",
    "\n",
    "\n",
    "def load_csv(filename: str) -> list[dict[str, str]]:\n",
    "    \"\"\"Load CSV from tests/data directory.\"\"\"\n",
    "    with open(DATA_DIR / filename, newline=\"\", encoding=\"utf-8\") as f:\n",
    "        return list(csv.DictReader(f))\n",
    "\n",
    "\n",
    "companies = load_csv(\"companies.csv\")\n",
    "products = load_csv(\"products.csv\")\n",
    "tickets = load_csv(\"support_tickets.csv\")\n",
    "\n",
    "print(f\"Companies: {len(companies)} rows\")\n",
    "print(f\"Products:  {len(products)} rows\")\n",
    "print(f\"Tickets:   {len(tickets)} rows\")\n",
    "print()\n",
    "print(\"Sample company:\", companies[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "models-header",
   "metadata": {},
   "source": [
    "## Define Output Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "output-models",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output models defined.\n"
     ]
    }
   ],
   "source": [
    "class IndustryClassification(BaseModel):\n",
    "    \"\"\"Classification of a company by industry sector.\"\"\"\n",
    "    sector: str = Field(description=\"Primary industry sector\")\n",
    "    sub_sector: str = Field(description=\"More specific sub-sector\")\n",
    "    is_public: bool = Field(description=\"Whether the company is publicly traded\")\n",
    "\n",
    "\n",
    "class SentimentAnalysis(BaseModel):\n",
    "    \"\"\"Sentiment analysis of a product review.\"\"\"\n",
    "    sentiment: Literal[\"positive\", \"negative\", \"mixed\"] = Field(description=\"Overall sentiment\")\n",
    "    score: float = Field(description=\"Score from 0.0 (negative) to 1.0 (positive)\")\n",
    "    key_themes: list[str] = Field(description=\"Main themes in the review (1-3 items)\")\n",
    "\n",
    "\n",
    "class TicketTriage(BaseModel):\n",
    "    \"\"\"Support ticket triage result.\"\"\"\n",
    "    category: str = Field(description=\"Category: billing, technical, shipping, account, or general\")\n",
    "    priority: Literal[\"low\", \"medium\", \"high\", \"urgent\"] = Field(description=\"Priority level\")\n",
    "    requires_human: bool = Field(description=\"Whether human escalation is needed\")\n",
    "    suggested_response: str = Field(description=\"Brief suggested response to the customer\")\n",
    "\n",
    "\n",
    "class CompanySummary(BaseModel):\n",
    "    \"\"\"Structured company summary.\"\"\"\n",
    "    one_liner: str = Field(description=\"One sentence description\")\n",
    "    industry: str = Field(description=\"Primary industry\")\n",
    "    company_size: Literal[\"startup\", \"small\", \"medium\", \"large\", \"enterprise\"] = Field(\n",
    "        description=\"Size classification based on employee count\"\n",
    "    )\n",
    "    age_years: int = Field(description=\"Approximate age in years\")\n",
    "\n",
    "\n",
    "print(\"Output models defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helper-header",
   "metadata": {},
   "source": [
    "## Helper: Pretty-Print Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "helpers",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_result(label: str, result: SmeltResult) -> None:\n",
    "    \"\"\"Pretty-print a SmeltResult.\"\"\"\n",
    "    status = \"SUCCESS\" if result.success else \"FAILED\"\n",
    "    m = result.metrics\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"  {label}\")\n",
    "    print(f\"  Status: {status}\")\n",
    "    print(f\"  Rows: {m.successful_rows}/{m.total_rows} successful\")\n",
    "    print(f\"  Batches: {m.successful_batches}/{m.total_batches} successful\")\n",
    "    print(f\"  Tokens: {m.input_tokens:,} in / {m.output_tokens:,} out\")\n",
    "    print(f\"  Retries: {m.total_retries} | Time: {m.wall_time_seconds:.2f}s\")\n",
    "    if result.errors:\n",
    "        print(f\"  Errors: {len(result.errors)}\")\n",
    "        for e in result.errors:\n",
    "            print(f\"    - Batch {e.batch_index}: {e.error_type} ({e.attempts} attempts)\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print()\n",
    "    for i, row in enumerate(result.data):\n",
    "        print(f\"  [{i}] {row}\")\n",
    "    # if len(result.data) > 3:\n",
    "    #     print(f\"  ... and {len(result.data) - 3} more rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test1-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Basic Classification — All 3 Providers\n",
    "\n",
    "Same task, same data, three different LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "test1-openai",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  OpenAI / gpt-4.1-mini — Company Classification\n",
      "  Status: SUCCESS\n",
      "  Rows: 10/10 successful\n",
      "  Batches: 1/1 successful\n",
      "  Tokens: 961 in / 231 out\n",
      "  Retries: 0 | Time: 3.20s\n",
      "======================================================================\n",
      "\n",
      "  [0] sector='Technology' sub_sector='Consumer Electronics & Software' is_public=True\n",
      "  [1] sector='Financial Services' sub_sector='Banking & Investment Services' is_public=True\n",
      "  [2] sector='Healthcare' sub_sector='Pharmaceuticals & Biotechnology' is_public=True\n",
      "  [3] sector='Automotive & Energy' sub_sector='Electric Vehicles & Clean Energy' is_public=True\n",
      "  [4] sector='Technology' sub_sector='Streaming Entertainment' is_public=True\n",
      "  [5] sector='Professional Services' sub_sector='Audit & Consulting' is_public=False\n",
      "  [6] sector='Technology' sub_sector='Music & Podcast Streaming Platform' is_public=True\n",
      "  [7] sector='Financial Services' sub_sector='Financial Infrastructure' is_public=False\n",
      "  [8] sector='Healthcare' sub_sector='Biotechnology' is_public=True\n",
      "  [9] sector='Technology' sub_sector='Online Marketplace for Lodging & Experiences' is_public=True\n"
     ]
    }
   ],
   "source": [
    "# OpenAI — GPT-4.1-mini\n",
    "model_openai = Model(provider=\"openai\", name=\"gpt-4.1-mini\", api_key=OPENAI_KEY)\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Classify each company by its primary industry sector and sub-sector. \"\n",
    "    \"Determine if the company is publicly traded.\",\n",
    "    output_model=IndustryClassification,\n",
    "    batch_size=10,\n",
    "    stop_on_exhaustion=False,\n",
    ")\n",
    "\n",
    "result = await job.arun(model_openai, data=companies)\n",
    "show_result(\"OpenAI / gpt-4.1-mini — Company Classification\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "test1-anthropic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  Anthropic / claude-sonnet-4 — Company Classification\n",
      "  Status: SUCCESS\n",
      "  Rows: 10/10 successful\n",
      "  Batches: 1/1 successful\n",
      "  Tokens: 1,386 in / 483 out\n",
      "  Retries: 0 | Time: 5.86s\n",
      "======================================================================\n",
      "\n",
      "  [0] sector='Technology' sub_sector='Consumer Electronics' is_public=True\n",
      "  [1] sector='Financial Services' sub_sector='Investment Banking' is_public=True\n",
      "  [2] sector='Healthcare' sub_sector='Pharmaceuticals' is_public=True\n",
      "  [3] sector='Automotive' sub_sector='Electric Vehicles' is_public=True\n",
      "  [4] sector='Media & Entertainment' sub_sector='Streaming Services' is_public=True\n",
      "  [5] sector='Professional Services' sub_sector='Consulting' is_public=False\n",
      "  [6] sector='Media & Entertainment' sub_sector='Music Streaming' is_public=True\n",
      "  [7] sector='Financial Services' sub_sector='Payment Processing' is_public=False\n",
      "  [8] sector='Healthcare' sub_sector='Biotechnology' is_public=True\n",
      "  [9] sector='Travel & Hospitality' sub_sector='Online Marketplace' is_public=True\n"
     ]
    }
   ],
   "source": [
    "# Anthropic — Claude Sonnet 4\n",
    "model_anthropic = Model(provider=\"anthropic\", name=\"claude-sonnet-4-20250514\", api_key=ANTHROPIC_KEY)\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Classify each company by its primary industry sector and sub-sector. \"\n",
    "    \"Determine if the company is publicly traded.\",\n",
    "    output_model=IndustryClassification,\n",
    "    batch_size=10,\n",
    "    stop_on_exhaustion=False,\n",
    ")\n",
    "\n",
    "result = await job.arun(model_anthropic, data=companies)\n",
    "show_result(\"Anthropic / claude-sonnet-4 — Company Classification\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "test1-gemini",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  Gemini / gemini-2.5-flash — Company Classification\n",
      "  Status: SUCCESS\n",
      "  Rows: 10/10 successful\n",
      "  Batches: 1/1 successful\n",
      "  Tokens: 943 in / 1,041 out\n",
      "  Retries: 0 | Time: 5.38s\n",
      "======================================================================\n",
      "\n",
      "  [0] sector='Technology' sub_sector='Consumer Electronics & Software' is_public=True\n",
      "  [1] sector='Financials' sub_sector='Investment Banking & Commercial Banking' is_public=True\n",
      "  [2] sector='Healthcare' sub_sector='Pharmaceuticals' is_public=True\n",
      "  [3] sector='Automotive' sub_sector='Electric Vehicles & Renewable Energy' is_public=True\n",
      "  [4] sector='Media & Entertainment' sub_sector='Streaming Services' is_public=True\n",
      "  [5] sector='Professional Services' sub_sector='Consulting & Accounting' is_public=False\n",
      "  [6] sector='Media & Entertainment' sub_sector='Music Streaming' is_public=True\n",
      "  [7] sector='Technology' sub_sector='Financial Technology' is_public=False\n",
      "  [8] sector='Healthcare' sub_sector='Biotechnology' is_public=True\n",
      "  [9] sector='Consumer Discretionary' sub_sector='Online Travel & Lodging' is_public=True\n"
     ]
    }
   ],
   "source": [
    "# Google Gemini — Gemini 2.5 Flash\n",
    "model_gemini = Model(provider=\"google_genai\", name=\"gemini-2.5-flash\", api_key=GEMINI_KEY)\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Classify each company by its primary industry sector and sub-sector. \"\n",
    "    \"Determine if the company is publicly traded.\",\n",
    "    output_model=IndustryClassification,\n",
    "    batch_size=10,\n",
    "    stop_on_exhaustion=False,\n",
    ")\n",
    "\n",
    "result = await job.arun(model_gemini, data=companies)\n",
    "show_result(\"Gemini / gemini-2.5-flash — Company Classification\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test2-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Sentiment Analysis — Score Validation\n",
    "\n",
    "Analyze product reviews and verify scores are in [0, 1] range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "test2-openai",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  OpenAI / gpt-4.1-mini — Sentiment Analysis\n",
      "  Status: SUCCESS\n",
      "  Rows: 10/10 successful\n",
      "  Batches: 2/2 successful\n",
      "  Tokens: 1,514 in / 308 out\n",
      "  Retries: 0 | Time: 3.83s\n",
      "======================================================================\n",
      "\n",
      "  [0] sentiment='positive' score=0.95 key_themes=['sound quality', 'comfort', 'long flights']\n",
      "  [1] sentiment='mixed' score=0.65 key_themes=['performance on hardwood', 'battery life']\n",
      "  [2] sentiment='positive' score=0.9 key_themes=['reading experience', 'glare-free display', 'portability']\n",
      "  [3] sentiment='positive' score=0.9 key_themes=['meal prep', 'ease of use', 'time saving']\n",
      "  [4] sentiment='mixed' score=0.6 key_themes=['warmth', 'seasonal suitability', 'material']\n",
      "  [5] sentiment='positive' score=0.9 key_themes=['kids enjoyment', 'screen quality']\n",
      "  [6] sentiment='positive' score=0.85 key_themes=['sound quality', 'portability', 'waterproof']\n",
      "  [7] sentiment='positive' score=0.95 key_themes=['ergonomics', 'pain relief', 'comfort']\n",
      "  [8] sentiment='positive' score=0.9 key_themes=['weight', 'value', 'cooking performance']\n",
      "  [9] sentiment='positive' score=0.9 key_themes=['robot vacuum', 'obstacle avoidance', 'reliability']\n",
      "\n",
      "Score validation:\n",
      "  [0] score=0.95 sentiment=positive valid=True themes=['sound quality', 'comfort', 'long flights']\n",
      "  [1] score=0.65 sentiment=mixed    valid=True themes=['performance on hardwood', 'battery life']\n",
      "  [2] score=0.90 sentiment=positive valid=True themes=['reading experience', 'glare-free display', 'portability']\n",
      "  [3] score=0.90 sentiment=positive valid=True themes=['meal prep', 'ease of use', 'time saving']\n",
      "  [4] score=0.60 sentiment=mixed    valid=True themes=['warmth', 'seasonal suitability', 'material']\n",
      "  [5] score=0.90 sentiment=positive valid=True themes=['kids enjoyment', 'screen quality']\n",
      "  [6] score=0.85 sentiment=positive valid=True themes=['sound quality', 'portability', 'waterproof']\n",
      "  [7] score=0.95 sentiment=positive valid=True themes=['ergonomics', 'pain relief', 'comfort']\n",
      "  [8] score=0.90 sentiment=positive valid=True themes=['weight', 'value', 'cooking performance']\n",
      "  [9] score=0.90 sentiment=positive valid=True themes=['robot vacuum', 'obstacle avoidance', 'reliability']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeevanprakash/Desktop/work/cydratech/llm-data-transformation/.venv/lib/python3.10/site-packages/pydantic/main.py:464: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `none` - serialized value may not be as expected [field_name='parsed', input_value=_SmeltBatch(rows=[_SmeltS...liability'], row_id=9)]), input_type=_SmeltBatch])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "/Users/jeevanprakash/Desktop/work/cydratech/llm-data-transformation/.venv/lib/python3.10/site-packages/pydantic/main.py:464: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `none` - serialized value may not be as expected [field_name='parsed', input_value=_SmeltBatch(rows=[_SmeltS...'material'], row_id=4)]), input_type=_SmeltBatch])\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    }
   ],
   "source": [
    "model = Model(provider=\"openai\", name=\"gpt-4.1-mini\", api_key=OPENAI_KEY, params={\"temperature\": 0})\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Analyze the sentiment of each product's customer_review. \"\n",
    "    \"Identify the overall sentiment, assign a score between 0.0 and 1.0, \"\n",
    "    \"and extract 1-3 key themes.\",\n",
    "    output_model=SentimentAnalysis,\n",
    "    batch_size=5,\n",
    "    concurrency=2,\n",
    "    stop_on_exhaustion=False,\n",
    ")\n",
    "\n",
    "result = await job.arun(model, data=products)\n",
    "show_result(\"OpenAI / gpt-4.1-mini — Sentiment Analysis\", result)\n",
    "\n",
    "# Validate scores\n",
    "print(\"\\nScore validation:\")\n",
    "for i, row in enumerate(result.data):\n",
    "    in_range = 0.0 <= row.score <= 1.0\n",
    "    print(f\"  [{i}] score={row.score:.2f} sentiment={row.sentiment:8s} valid={in_range} themes={row.key_themes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "test2-anthropic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  Anthropic / claude-haiku-4.5 — Sentiment Analysis\n",
      "  Status: SUCCESS\n",
      "  Rows: 10/10 successful\n",
      "  Batches: 2/2 successful\n",
      "  Tokens: 2,915 in / 600 out\n",
      "  Retries: 0 | Time: 2.68s\n",
      "======================================================================\n",
      "\n",
      "  [0] sentiment='positive' score=0.95 key_themes=['sound quality', 'comfort', 'long-distance use']\n",
      "  [1] sentiment='mixed' score=0.65 key_themes=['performance on hardwood', 'battery life limitation']\n",
      "  [2] sentiment='positive' score=0.9 key_themes=['portability', 'display quality', 'versatile usage']\n",
      "  [3] sentiment='positive' score=0.85 key_themes=['meal preparation', 'convenience', 'time-saving']\n",
      "  [4] sentiment='mixed' score=0.6 key_themes=['seasonal versatility', 'temperature limitations', 'lightweight design']\n",
      "  [5] sentiment='positive' score=0.95 key_themes=['display quality', 'family satisfaction', 'product appeal']\n",
      "  [6] sentiment='positive' score=0.9 key_themes=['audio quality', 'portability', 'durability']\n",
      "  [7] sentiment='positive' score=0.92 key_themes=['health benefits', 'ergonomics', 'value proposition']\n",
      "  [8] sentiment='positive' score=0.88 key_themes=['quality', 'durability', 'cooking performance']\n",
      "  [9] sentiment='positive' score=0.89 key_themes=['reliability', 'innovation', 'practical functionality']\n",
      "\n",
      "Score validation:\n",
      "  [0] score=0.95 sentiment=positive valid=True themes=['sound quality', 'comfort', 'long-distance use']\n",
      "  [1] score=0.65 sentiment=mixed    valid=True themes=['performance on hardwood', 'battery life limitation']\n",
      "  [2] score=0.90 sentiment=positive valid=True themes=['portability', 'display quality', 'versatile usage']\n",
      "  [3] score=0.85 sentiment=positive valid=True themes=['meal preparation', 'convenience', 'time-saving']\n",
      "  [4] score=0.60 sentiment=mixed    valid=True themes=['seasonal versatility', 'temperature limitations', 'lightweight design']\n",
      "  [5] score=0.95 sentiment=positive valid=True themes=['display quality', 'family satisfaction', 'product appeal']\n",
      "  [6] score=0.90 sentiment=positive valid=True themes=['audio quality', 'portability', 'durability']\n",
      "  [7] score=0.92 sentiment=positive valid=True themes=['health benefits', 'ergonomics', 'value proposition']\n",
      "  [8] score=0.88 sentiment=positive valid=True themes=['quality', 'durability', 'cooking performance']\n",
      "  [9] score=0.89 sentiment=positive valid=True themes=['reliability', 'innovation', 'practical functionality']\n"
     ]
    }
   ],
   "source": [
    "model = Model(provider=\"anthropic\", name=\"claude-haiku-4-5-20251001\", api_key=ANTHROPIC_KEY, params={\"temperature\": 0})\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Analyze the sentiment of each product's customer_review. \"\n",
    "    \"Identify the overall sentiment, assign a score between 0.0 and 1.0, \"\n",
    "    \"and extract 1-3 key themes.\",\n",
    "    output_model=SentimentAnalysis,\n",
    "    batch_size=5,\n",
    "    concurrency=2,\n",
    "    stop_on_exhaustion=False,\n",
    ")\n",
    "\n",
    "result = await job.arun(model, data=products)\n",
    "show_result(\"Anthropic / claude-haiku-4.5 — Sentiment Analysis\", result)\n",
    "\n",
    "print(\"\\nScore validation:\")\n",
    "for i, row in enumerate(result.data):\n",
    "    in_range = 0.0 <= row.score <= 1.0\n",
    "    print(f\"  [{i}] score={row.score:.2f} sentiment={row.sentiment:8s} valid={in_range} themes={row.key_themes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test2-gemini",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(provider=\"google_genai\", name=\"gemini-2.0-flash\", api_key=GEMINI_KEY, params={\"temperature\": 0})\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Analyze the sentiment of each product's customer_review. \"\n",
    "    \"Identify the overall sentiment, assign a score between 0.0 and 1.0, \"\n",
    "    \"and extract 1-3 key themes.\",\n",
    "    output_model=SentimentAnalysis,\n",
    "    batch_size=5,\n",
    "    concurrency=2,\n",
    "    stop_on_exhaustion=False,\n",
    ")\n",
    "\n",
    "result = await job.arun(model, data=products)\n",
    "show_result(\"Gemini / gemini-2.0-flash — Sentiment Analysis\", result)\n",
    "\n",
    "print(\"\\nScore validation:\")\n",
    "for i, row in enumerate(result.data):\n",
    "    in_range = 0.0 <= row.score <= 1.0\n",
    "    print(f\"  [{i}] score={row.score:.2f} sentiment={row.sentiment:8s} valid={in_range} themes={row.key_themes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test3-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Support Ticket Triage — Complex Schema\n",
    "\n",
    "Tests Literal types, booleans, and longer text generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test3-openai",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(provider=\"openai\", name=\"gpt-4.1-mini\", api_key=OPENAI_KEY)\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Triage each support ticket. Classify by category (billing, technical, \"\n",
    "    \"shipping, account, or general), assign priority, determine if human escalation \"\n",
    "    \"is needed, and write a brief suggested response.\",\n",
    "    output_model=TicketTriage,\n",
    "    batch_size=5,\n",
    "    concurrency=2,\n",
    "    stop_on_exhaustion=False,\n",
    ")\n",
    "\n",
    "result = await job.arun(model, data=tickets)\n",
    "show_result(\"OpenAI / gpt-4.1-mini — Ticket Triage\", result)\n",
    "\n",
    "print(\"\\nFull triage results:\")\n",
    "for i, row in enumerate(result.data):\n",
    "    print(f\"\\n  [{i}] {tickets[i]['ticket_id']}\")\n",
    "    print(f\"      Category: {row.category} | Priority: {row.priority} | Human: {row.requires_human}\")\n",
    "    print(f\"      Response: {row.suggested_response[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test3-anthropic",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(provider=\"anthropic\", name=\"claude-sonnet-4-20250514\", api_key=ANTHROPIC_KEY)\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Triage each support ticket. Classify by category (billing, technical, \"\n",
    "    \"shipping, account, or general), assign priority, determine if human escalation \"\n",
    "    \"is needed, and write a brief suggested response.\",\n",
    "    output_model=TicketTriage,\n",
    "    batch_size=5,\n",
    "    concurrency=2,\n",
    "    stop_on_exhaustion=False,\n",
    ")\n",
    "\n",
    "result = await job.arun(model, data=tickets)\n",
    "show_result(\"Anthropic / claude-sonnet-4 — Ticket Triage\", result)\n",
    "\n",
    "print(\"\\nFull triage results:\")\n",
    "for i, row in enumerate(result.data):\n",
    "    print(f\"\\n  [{i}] {tickets[i]['ticket_id']}\")\n",
    "    print(f\"      Category: {row.category} | Priority: {row.priority} | Human: {row.requires_human}\")\n",
    "    print(f\"      Response: {row.suggested_response[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test3-gemini",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(provider=\"google_genai\", name=\"gemini-2.5-flash\", api_key=GEMINI_KEY)\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Triage each support ticket. Classify by category (billing, technical, \"\n",
    "    \"shipping, account, or general), assign priority, determine if human escalation \"\n",
    "    \"is needed, and write a brief suggested response.\",\n",
    "    output_model=TicketTriage,\n",
    "    batch_size=5,\n",
    "    concurrency=2,\n",
    "    stop_on_exhaustion=False,\n",
    ")\n",
    "\n",
    "result = await job.arun(model, data=tickets)\n",
    "show_result(\"Gemini / gemini-2.5-flash — Ticket Triage\", result)\n",
    "\n",
    "print(\"\\nFull triage results:\")\n",
    "for i, row in enumerate(result.data):\n",
    "    print(f\"\\n  [{i}] {tickets[i]['ticket_id']}\")\n",
    "    print(f\"      Category: {row.category} | Priority: {row.priority} | Human: {row.requires_human}\")\n",
    "    print(f\"      Response: {row.suggested_response[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test4-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Parameter Tuning — Temperature Comparison\n",
    "\n",
    "Compare temperature=0 (deterministic) vs temperature=1.0 (creative) on the same task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test4-temp",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_subset = companies[:3]\n",
    "\n",
    "for temp in [0, 0.5, 1.0]:\n",
    "    model = Model(\n",
    "        provider=\"openai\", name=\"gpt-4.1-mini\", api_key=OPENAI_KEY,\n",
    "        params={\"temperature\": temp},\n",
    "    )\n",
    "    job = Job(\n",
    "        prompt=\"Classify each company by industry sector.\",\n",
    "        output_model=IndustryClassification,\n",
    "        batch_size=10,\n",
    "        stop_on_exhaustion=False,\n",
    "    )\n",
    "    result = await job.arun(model, data=data_subset)\n",
    "    show_result(f\"OpenAI / gpt-4.1-mini — temp={temp}\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test4-top-p",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anthropic: top_p and top_k\n",
    "for top_p in [0.5, 0.9]:\n",
    "    model = Model(\n",
    "        provider=\"anthropic\", name=\"claude-haiku-4-5-20251001\", api_key=ANTHROPIC_KEY,\n",
    "        params={\"temperature\": 0.7, \"top_p\": top_p},\n",
    "    )\n",
    "    job = Job(\n",
    "        prompt=\"Classify each company by industry sector.\",\n",
    "        output_model=IndustryClassification,\n",
    "        batch_size=10,\n",
    "        stop_on_exhaustion=False,\n",
    "    )\n",
    "    result = await job.arun(model, data=data_subset)\n",
    "    show_result(f\"Anthropic / claude-haiku-4.5 — top_p={top_p}\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test5-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Batch Configuration — Size & Concurrency\n",
    "\n",
    "Compare different batch_size and concurrency settings on the same dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test5-batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    {\"batch_size\": 10, \"concurrency\": 1, \"label\": \"1 batch, serial\"},\n",
    "    {\"batch_size\": 5, \"concurrency\": 2, \"label\": \"2 batches, conc=2\"},\n",
    "    {\"batch_size\": 2, \"concurrency\": 5, \"label\": \"5 batches, conc=5\"},\n",
    "    {\"batch_size\": 1, \"concurrency\": 10, \"label\": \"10 batches, conc=10\"},\n",
    "]\n",
    "\n",
    "model = Model(provider=\"openai\", name=\"gpt-4.1-mini\", api_key=OPENAI_KEY, params={\"temperature\": 0})\n",
    "\n",
    "for cfg in configs:\n",
    "    job = Job(\n",
    "        prompt=\"Classify each company by industry sector.\",\n",
    "        output_model=IndustryClassification,\n",
    "        batch_size=cfg[\"batch_size\"],\n",
    "        concurrency=cfg[\"concurrency\"],\n",
    "        stop_on_exhaustion=False,\n",
    "    )\n",
    "    result = await job.arun(model, data=companies)\n",
    "    show_result(f\"Config: {cfg['label']} (batch={cfg['batch_size']}, conc={cfg['concurrency']})\", result)\n",
    "    \n",
    "    # Verify all rows present and in order\n",
    "    assert len(result.data) == len(companies), f\"Row count mismatch: {len(result.data)} vs {len(companies)}\"\n",
    "    print(f\"  Row ordering verified: {len(result.data)} rows in correct order\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test6-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Error Handling — stop_on_exhaustion\n",
    "\n",
    "Demonstrate graceful error handling when `stop_on_exhaustion=False` collects errors,\n",
    "and when `stop_on_exhaustion=True` raises `SmeltExhaustionError` with partial results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test6-collect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_on_exhaustion=False: errors are collected, successful batches still returned\n",
    "model = Model(provider=\"openai\", name=\"gpt-4.1-mini\", api_key=OPENAI_KEY, params={\"temperature\": 0})\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Create a concise structured summary for each company. \"\n",
    "    \"Calculate age based on founded year (current year is 2026).\",\n",
    "    output_model=CompanySummary,\n",
    "    batch_size=5,\n",
    "    concurrency=2,\n",
    "    max_retries=2,\n",
    "    stop_on_exhaustion=False,  # collect errors, don't raise\n",
    ")\n",
    "\n",
    "result = await job.arun(model, data=companies)\n",
    "show_result(\"Company Summary (stop_on_exhaustion=False)\", result)\n",
    "\n",
    "print(f\"\\nsuccess property: {result.success}\")\n",
    "print(f\"result.data has {len(result.data)} rows\")\n",
    "print(f\"result.errors has {len(result.errors)} errors\")\n",
    "print(f\"result.metrics: {result.metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test6-exhaustion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_on_exhaustion=True with a valid request — should succeed without raising\n",
    "model = Model(provider=\"openai\", name=\"gpt-4.1-mini\", api_key=OPENAI_KEY, params={\"temperature\": 0})\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Classify each company by industry sector.\",\n",
    "    output_model=IndustryClassification,\n",
    "    batch_size=10,\n",
    "    max_retries=3,\n",
    "    stop_on_exhaustion=True,  # will raise on failure\n",
    ")\n",
    "\n",
    "try:\n",
    "    result = await job.arun(model, data=companies)\n",
    "    show_result(\"Classification (stop_on_exhaustion=True, no error expected)\", result)\n",
    "    print(\"No exception raised — all batches succeeded.\")\n",
    "except SmeltExhaustionError as e:\n",
    "    print(f\"SmeltExhaustionError: {e}\")\n",
    "    print(f\"Partial results: {len(e.partial_result.data)} rows succeeded\")\n",
    "    print(f\"Errors: {len(e.partial_result.errors)} batches failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test7-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Async Execution\n",
    "\n",
    "Use `await job.arun()` directly (works in Jupyter notebooks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "test7-async-openai",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeevanprakash/Desktop/work/cydratech/llm-data-transformation/.venv/lib/python3.10/site-packages/pydantic/main.py:464: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `none` - serialized value may not be as expected [field_name='parsed', input_value=_SmeltBatch(rows=[_SmeltI...public=True, row_id=9)]), input_type=_SmeltBatch])\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  OpenAI / gpt-4.1-mini — Async (batch=3, conc=4)\n",
      "  Status: SUCCESS\n",
      "  Rows: 10/10 successful\n",
      "  Batches: 4/4 successful\n",
      "  Tokens: 2,004 in / 245 out\n",
      "  Retries: 0 | Time: 2.54s\n",
      "======================================================================\n",
      "\n",
      "  [0] sector='Technology' sub_sector='Consumer Electronics and Software' is_public=True\n",
      "  [1] sector='Financial Services' sub_sector='Investment Banking and Financial Services' is_public=True\n",
      "  [2] sector='Healthcare' sub_sector='Pharmaceuticals and Biotechnology' is_public=True\n",
      "  ... and 7 more rows\n",
      "  Batches: 4 (ceil(10/3) = 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeevanprakash/Desktop/work/cydratech/llm-data-transformation/.venv/lib/python3.10/site-packages/pydantic/main.py:464: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `none` - serialized value may not be as expected [field_name='parsed', input_value=_SmeltBatch(rows=[_SmeltI...ublic=False, row_id=5)]), input_type=_SmeltBatch])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "/Users/jeevanprakash/Desktop/work/cydratech/llm-data-transformation/.venv/lib/python3.10/site-packages/pydantic/main.py:464: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `none` - serialized value may not be as expected [field_name='parsed', input_value=_SmeltBatch(rows=[_SmeltI...public=True, row_id=2)]), input_type=_SmeltBatch])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "/Users/jeevanprakash/Desktop/work/cydratech/llm-data-transformation/.venv/lib/python3.10/site-packages/pydantic/main.py:464: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `none` - serialized value may not be as expected [field_name='parsed', input_value=_SmeltBatch(rows=[_SmeltI...public=True, row_id=8)]), input_type=_SmeltBatch])\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    }
   ],
   "source": [
    "model = Model(provider=\"openai\", name=\"gpt-4.1-mini\", api_key=OPENAI_KEY, params={\"temperature\": 0})\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Classify each company by industry sector.\",\n",
    "    output_model=IndustryClassification,\n",
    "    batch_size=3,\n",
    "    concurrency=4,\n",
    "    stop_on_exhaustion=False,\n",
    ")\n",
    "\n",
    "result = await job.arun(model, data=companies)\n",
    "show_result(\"OpenAI / gpt-4.1-mini — Async (batch=3, conc=4)\", result)\n",
    "print(f\"  Batches: {result.metrics.total_batches} (ceil(10/3) = 4)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "test7-async-anthropic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  Anthropic / claude-haiku-4.5 — Async Sentiment\n",
      "  Status: SUCCESS\n",
      "  Rows: 10/10 successful\n",
      "  Batches: 2/2 successful\n",
      "  Tokens: 2,847 in / 598 out\n",
      "  Retries: 0 | Time: 2.82s\n",
      "======================================================================\n",
      "\n",
      "  [0] sentiment='positive' score=0.95 key_themes=['sound quality', 'comfort', 'travel']\n",
      "  [1] sentiment='mixed' score=0.65 key_themes=['performance', 'battery life', 'flooring']\n",
      "  [2] sentiment='positive' score=0.9 key_themes=['portability', 'display quality', 'reading experience']\n",
      "  ... and 7 more rows\n"
     ]
    }
   ],
   "source": [
    "model = Model(provider=\"anthropic\", name=\"claude-haiku-4-5-20251001\", api_key=ANTHROPIC_KEY)\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Analyze the sentiment of each product review.\",\n",
    "    output_model=SentimentAnalysis,\n",
    "    batch_size=5,\n",
    "    concurrency=2,\n",
    "    stop_on_exhaustion=False,\n",
    ")\n",
    "\n",
    "result = await job.arun(model, data=products)\n",
    "show_result(\"Anthropic / claude-haiku-4.5 — Async Sentiment\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "test7-async-gemini",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  Gemini / gemini-2.5-flash — Async Ticket Triage\n",
      "  Status: SUCCESS\n",
      "  Rows: 10/10 successful\n",
      "  Batches: 1/1 successful\n",
      "  Tokens: 1,128 in / 1,358 out\n",
      "  Retries: 0 | Time: 7.25s\n",
      "======================================================================\n",
      "\n",
      "  [0] category='shipping' priority='urgent' requires_human=True suggested_response='Apologize for the damaged item and arrange for an urgent replacement.'\n",
      "  [1] category='billing' priority='low' requires_human=False suggested_response='Provide instructions on how to change subscription billing cycles.'\n",
      "  [2] category='technical' priority='high' requires_human=True suggested_response='Apologize for the issue and offer troubleshooting steps or escalate to technical support.'\n",
      "  ... and 7 more rows\n"
     ]
    }
   ],
   "source": [
    "model = Model(provider=\"google_genai\", name=\"gemini-2.5-flash\", api_key=GEMINI_KEY)\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Triage each support ticket with category, priority, escalation need, \"\n",
    "    \"and a suggested response.\",\n",
    "    output_model=TicketTriage,\n",
    "    batch_size=10,\n",
    "    stop_on_exhaustion=False,\n",
    ")\n",
    "\n",
    "result = await job.arun(model, data=tickets)\n",
    "show_result(\"Gemini / gemini-2.5-flash — Async Ticket Triage\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "All tests complete. Smelt successfully:\n",
    "- Transforms structured data through OpenAI, Anthropic, and Google Gemini\n",
    "- Returns strictly typed Pydantic models\n",
    "- Handles batching and concurrency\n",
    "- Provides detailed metrics (tokens, timing, retries)\n",
    "- Works in both sync (`job.run()`) and async (`await job.arun()`) modes\n",
    "\n",
    "> **Note:** Jupyter notebooks run inside an event loop, so all cells use `await job.arun()`.\n",
    "> Use `job.run()` in regular Python scripts where no event loop is running."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0427289a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff8dfbc6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac374d2d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06c71f32",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
