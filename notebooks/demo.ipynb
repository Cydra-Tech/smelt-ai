{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": "# Smelt AI — Live Demo\n\nInteractive walkthrough of smelt-ai across **OpenAI**, **Anthropic**, and **Google Gemini**.\n\nTests:\n1. Basic classification (all 3 providers)\n2. Sentiment analysis with score validation\n3. Support ticket triage (complex schema)\n4. Parameter tuning (temperature, top_p)\n5. Batch configuration (batch_size, concurrency)\n6. Error handling (stop_on_exhaustion)\n7. Async execution"
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI key:    set\n",
      "Anthropic key: set\n",
      "Gemini key:    set\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Literal\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from smelt import Model, Job, SmeltResult, SmeltMetrics, BatchError\n",
    "from smelt.errors import SmeltExhaustionError\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "ANTHROPIC_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "GEMINI_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "print(f\"OpenAI key:    {'set' if OPENAI_KEY else 'MISSING'}\")\n",
    "print(f\"Anthropic key: {'set' if ANTHROPIC_KEY else 'MISSING'}\")\n",
    "print(f\"Gemini key:    {'set' if GEMINI_KEY else 'MISSING'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-header",
   "metadata": {},
   "source": [
    "## Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "load-data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Companies: 10 rows\n",
      "Products:  10 rows\n",
      "Tickets:   10 rows\n",
      "\n",
      "Sample company: {'name': 'Apple Inc.', 'description': 'Designs and manufactures consumer electronics and software', 'founded': '1976', 'headquarters': 'Cupertino CA', 'employees': '164000'}\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = Path(\"../tests/data\")\n",
    "\n",
    "\n",
    "def load_csv(filename: str) -> list[dict[str, str]]:\n",
    "    \"\"\"Load CSV from tests/data directory.\"\"\"\n",
    "    with open(DATA_DIR / filename, newline=\"\", encoding=\"utf-8\") as f:\n",
    "        return list(csv.DictReader(f))\n",
    "\n",
    "\n",
    "companies = load_csv(\"companies.csv\")\n",
    "products = load_csv(\"products.csv\")\n",
    "tickets = load_csv(\"support_tickets.csv\")\n",
    "\n",
    "print(f\"Companies: {len(companies)} rows\")\n",
    "print(f\"Products:  {len(products)} rows\")\n",
    "print(f\"Tickets:   {len(tickets)} rows\")\n",
    "print()\n",
    "print(\"Sample company:\", companies[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "models-header",
   "metadata": {},
   "source": [
    "## Define Output Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "output-models",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output models defined.\n"
     ]
    }
   ],
   "source": [
    "class IndustryClassification(BaseModel):\n",
    "    \"\"\"Classification of a company by industry sector.\"\"\"\n",
    "    sector: str = Field(description=\"Primary industry sector\")\n",
    "    sub_sector: str = Field(description=\"More specific sub-sector\")\n",
    "    is_public: bool = Field(description=\"Whether the company is publicly traded\")\n",
    "\n",
    "\n",
    "class SentimentAnalysis(BaseModel):\n",
    "    \"\"\"Sentiment analysis of a product review.\"\"\"\n",
    "    sentiment: Literal[\"positive\", \"negative\", \"mixed\"] = Field(description=\"Overall sentiment\")\n",
    "    score: float = Field(description=\"Score from 0.0 (negative) to 1.0 (positive)\")\n",
    "    key_themes: list[str] = Field(description=\"Main themes in the review (1-3 items)\")\n",
    "\n",
    "\n",
    "class TicketTriage(BaseModel):\n",
    "    \"\"\"Support ticket triage result.\"\"\"\n",
    "    category: str = Field(description=\"Category: billing, technical, shipping, account, or general\")\n",
    "    priority: Literal[\"low\", \"medium\", \"high\", \"urgent\"] = Field(description=\"Priority level\")\n",
    "    requires_human: bool = Field(description=\"Whether human escalation is needed\")\n",
    "    suggested_response: str = Field(description=\"Brief suggested response to the customer\")\n",
    "\n",
    "\n",
    "class CompanySummary(BaseModel):\n",
    "    \"\"\"Structured company summary.\"\"\"\n",
    "    one_liner: str = Field(description=\"One sentence description\")\n",
    "    industry: str = Field(description=\"Primary industry\")\n",
    "    company_size: Literal[\"startup\", \"small\", \"medium\", \"large\", \"enterprise\"] = Field(\n",
    "        description=\"Size classification based on employee count\"\n",
    "    )\n",
    "    age_years: int = Field(description=\"Approximate age in years\")\n",
    "\n",
    "\n",
    "print(\"Output models defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helper-header",
   "metadata": {},
   "source": [
    "## Helper: Pretty-Print Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "helpers",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_result(label: str, result: SmeltResult) -> None:\n",
    "    \"\"\"Pretty-print a SmeltResult.\"\"\"\n",
    "    status = \"SUCCESS\" if result.success else \"FAILED\"\n",
    "    m = result.metrics\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"  {label}\")\n",
    "    print(f\"  Status: {status}\")\n",
    "    print(f\"  Rows: {m.successful_rows}/{m.total_rows} successful\")\n",
    "    print(f\"  Batches: {m.successful_batches}/{m.total_batches} successful\")\n",
    "    print(f\"  Tokens: {m.input_tokens:,} in / {m.output_tokens:,} out\")\n",
    "    print(f\"  Retries: {m.total_retries} | Time: {m.wall_time_seconds:.2f}s\")\n",
    "    if result.errors:\n",
    "        print(f\"  Errors: {len(result.errors)}\")\n",
    "        for e in result.errors:\n",
    "            print(f\"    - Batch {e.batch_index}: {e.error_type} ({e.attempts} attempts)\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print()\n",
    "    for i, row in enumerate(result.data):\n",
    "        print(f\"  [{i}] {row}\")\n",
    "    if len(result.data) > 3:\n",
    "        print(f\"  ... and {len(result.data) - 3} more rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test1-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Basic Classification — All 3 Providers\n",
    "\n",
    "Same task, same data, three different LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "test1-openai",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  OpenAI / gpt-4.1-mini — Company Classification\n",
      "  Status: SUCCESS\n",
      "  Rows: 10/10 successful\n",
      "  Batches: 1/1 successful\n",
      "  Tokens: 961 in / 234 out\n",
      "  Retries: 0 | Time: 3.78s\n",
      "======================================================================\n",
      "\n",
      "  [0] sector='Information Technology' sub_sector='Consumer Electronics and Software' is_public=True\n",
      "  [1] sector='Financials' sub_sector='Investment Banking and Financial Services' is_public=True\n",
      "  [2] sector='Healthcare' sub_sector='Pharmaceuticals and Biotechnology' is_public=True\n",
      "  [3] sector='Consumer Discretionary' sub_sector='Electric Vehicles and Clean Energy' is_public=True\n",
      "  [4] sector='Communication Services' sub_sector='Streaming Entertainment' is_public=True\n",
      "  [5] sector='Industrials' sub_sector='Professional Services' is_public=False\n",
      "  [6] sector='Communication Services' sub_sector='Digital Music and Podcast Streaming' is_public=True\n",
      "  [7] sector='Information Technology' sub_sector='Financial Technology' is_public=False\n",
      "  [8] sector='Healthcare' sub_sector='Biotechnology' is_public=True\n",
      "  [9] sector='Consumer Discretionary' sub_sector='Online Marketplace for Lodging' is_public=True\n",
      "  ... and 7 more rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeevanprakash/Desktop/work/cydratech/llm-data-transformation/.venv/lib/python3.10/site-packages/pydantic/main.py:464: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `none` - serialized value may not be as expected [field_name='parsed', input_value=_SmeltBatch(rows=[_SmeltI...public=True, row_id=9)]), input_type=_SmeltBatch])\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    }
   ],
   "source": [
    "# OpenAI — GPT-4.1-mini\n",
    "model_openai = Model(provider=\"openai\", name=\"gpt-4.1-mini\", api_key=OPENAI_KEY)\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Classify each company by its primary industry sector and sub-sector. \"\n",
    "    \"Determine if the company is publicly traded.\",\n",
    "    output_model=IndustryClassification,\n",
    "    batch_size=10,\n",
    "    stop_on_exhaustion=False,\n",
    ")\n",
    "\n",
    "result = await job.arun(model_openai, data=companies)\n",
    "show_result(\"OpenAI / gpt-4.1-mini — Company Classification\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "test1-anthropic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  Anthropic / claude-sonnet-4 — Company Classification\n",
      "  Status: SUCCESS\n",
      "  Rows: 10/10 successful\n",
      "  Batches: 1/1 successful\n",
      "  Tokens: 1,386 in / 474 out\n",
      "  Retries: 0 | Time: 5.74s\n",
      "======================================================================\n",
      "\n",
      "  [0] sector='Technology' sub_sector='Consumer Electronics' is_public=True\n",
      "  [1] sector='Financial Services' sub_sector='Investment Banking' is_public=True\n",
      "  [2] sector='Healthcare' sub_sector='Pharmaceuticals' is_public=True\n",
      "  [3] sector='Automotive' sub_sector='Electric Vehicles' is_public=True\n",
      "  [4] sector='Technology' sub_sector='Media Streaming' is_public=True\n",
      "  [5] sector='Professional Services' sub_sector='Consulting' is_public=False\n",
      "  [6] sector='Technology' sub_sector='Digital Media' is_public=True\n",
      "  [7] sector='Financial Services' sub_sector='Payment Processing' is_public=False\n",
      "  [8] sector='Healthcare' sub_sector='Biotechnology' is_public=True\n",
      "  [9] sector='Technology' sub_sector='Online Marketplace' is_public=True\n",
      "  ... and 7 more rows\n"
     ]
    }
   ],
   "source": [
    "# Anthropic — Claude Sonnet 4\n",
    "model_anthropic = Model(provider=\"anthropic\", name=\"claude-sonnet-4-20250514\", api_key=ANTHROPIC_KEY)\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Classify each company by its primary industry sector and sub-sector. \"\n",
    "    \"Determine if the company is publicly traded.\",\n",
    "    output_model=IndustryClassification,\n",
    "    batch_size=10,\n",
    "    stop_on_exhaustion=False,\n",
    ")\n",
    "\n",
    "result = await job.arun(model_anthropic, data=companies)\n",
    "show_result(\"Anthropic / claude-sonnet-4 — Company Classification\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "test1-gemini",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Gemini — Gemini 2.5 Flash\n",
    "model_gemini = Model(provider=\"google_genai\", name=\"gemini-2.5-flash\", api_key=GEMINI_KEY)\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Classify each company by its primary industry sector and sub-sector. \"\n",
    "    \"Determine if the company is publicly traded.\",\n",
    "    output_model=IndustryClassification,\n",
    "    batch_size=10,\n",
    "    stop_on_exhaustion=False,\n",
    ")\n",
    "\n",
    "result = await job.arun(model_gemini, data=companies)\n",
    "show_result(\"Gemini / gemini-2.5-flash — Company Classification\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test2-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Sentiment Analysis — Score Validation\n",
    "\n",
    "Analyze product reviews and verify scores are in [0, 1] range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "test2-openai",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeevanprakash/Desktop/work/cydratech/llm-data-transformation/.venv/lib/python3.10/site-packages/pydantic/main.py:464: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `none` - serialized value may not be as expected [field_name='parsed', input_value=_SmeltBatch(rows=[_SmeltS...nvenience'], row_id=9)]), input_type=_SmeltBatch])\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  OpenAI / gpt-4.1-mini — Sentiment Analysis\n",
      "  Status: SUCCESS\n",
      "  Rows: 10/10 successful\n",
      "  Batches: 2/2 successful\n",
      "  Tokens: 1,514 in / 306 out\n",
      "  Retries: 0 | Time: 3.09s\n",
      "======================================================================\n",
      "\n",
      "  [0] sentiment='positive' score=0.9 key_themes=['sound quality', 'comfort', 'long flights']\n",
      "  [1] sentiment='mixed' score=0.6 key_themes=['performance on hardwood', 'battery life']\n",
      "  [2] sentiment='positive' score=0.95 key_themes=['reading experience', 'portability', 'glare-free display']\n",
      "  [3] sentiment='positive' score=0.9 key_themes=['meal preparation', 'ease of use', 'time-saving']\n",
      "  [4] sentiment='mixed' score=0.5 key_themes=['warmth', 'seasonal suitability']\n",
      "  [5] sentiment='positive' score=0.9 key_themes=['kids enjoyment', 'screen quality']\n",
      "  [6] sentiment='positive' score=0.85 key_themes=['sound quality', 'portability', 'waterproof']\n",
      "  [7] sentiment='positive' score=0.9 key_themes=['ergonomics', 'pain relief', 'comfort']\n",
      "  [8] sentiment='positive' score=0.8 key_themes=['weight', 'value', 'cooking versatility']\n",
      "  [9] sentiment='positive' score=0.9 key_themes=['functionality', 'obstacle avoidance', 'convenience']\n",
      "\n",
      "Score validation:\n",
      "  [0] score=0.90 sentiment=positive valid=True themes=['sound quality', 'comfort', 'long flights']\n",
      "  [1] score=0.60 sentiment=mixed    valid=True themes=['performance on hardwood', 'battery life']\n",
      "  [2] score=0.95 sentiment=positive valid=True themes=['reading experience', 'portability', 'glare-free display']\n",
      "  [3] score=0.90 sentiment=positive valid=True themes=['meal preparation', 'ease of use', 'time-saving']\n",
      "  [4] score=0.50 sentiment=mixed    valid=True themes=['warmth', 'seasonal suitability']\n",
      "  [5] score=0.90 sentiment=positive valid=True themes=['kids enjoyment', 'screen quality']\n",
      "  [6] score=0.85 sentiment=positive valid=True themes=['sound quality', 'portability', 'waterproof']\n",
      "  [7] score=0.90 sentiment=positive valid=True themes=['ergonomics', 'pain relief', 'comfort']\n",
      "  [8] score=0.80 sentiment=positive valid=True themes=['weight', 'value', 'cooking versatility']\n",
      "  [9] score=0.90 sentiment=positive valid=True themes=['functionality', 'obstacle avoidance', 'convenience']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeevanprakash/Desktop/work/cydratech/llm-data-transformation/.venv/lib/python3.10/site-packages/pydantic/main.py:464: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `none` - serialized value may not be as expected [field_name='parsed', input_value=_SmeltBatch(rows=[_SmeltS...itability'], row_id=4)]), input_type=_SmeltBatch])\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    }
   ],
   "source": [
    "model = Model(provider=\"openai\", name=\"gpt-4.1-mini\", api_key=OPENAI_KEY, params={\"temperature\": 0})\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Analyze the sentiment of each product's customer_review. \"\n",
    "    \"Identify the overall sentiment, assign a score between 0.0 and 1.0, \"\n",
    "    \"and extract 1-3 key themes.\",\n",
    "    output_model=SentimentAnalysis,\n",
    "    batch_size=5,\n",
    "    concurrency=2,\n",
    "    stop_on_exhaustion=False,\n",
    ")\n",
    "\n",
    "result = await job.arun(model, data=products)\n",
    "show_result(\"OpenAI / gpt-4.1-mini — Sentiment Analysis\", result)\n",
    "\n",
    "# Validate scores\n",
    "print(\"\\nScore validation:\")\n",
    "for i, row in enumerate(result.data):\n",
    "    in_range = 0.0 <= row.score <= 1.0\n",
    "    print(f\"  [{i}] score={row.score:.2f} sentiment={row.sentiment:8s} valid={in_range} themes={row.key_themes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "test2-anthropic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  Anthropic / claude-haiku-4.5 — Sentiment Analysis\n",
      "  Status: SUCCESS\n",
      "  Rows: 10/10 successful\n",
      "  Batches: 2/2 successful\n",
      "  Tokens: 2,915 in / 600 out\n",
      "  Retries: 0 | Time: 2.62s\n",
      "======================================================================\n",
      "\n",
      "  [0] sentiment='positive' score=0.95 key_themes=['sound quality', 'comfort', 'long-distance use']\n",
      "  [1] sentiment='mixed' score=0.65 key_themes=['performance on hardwood', 'battery life limitation']\n",
      "  [2] sentiment='positive' score=0.9 key_themes=['portability', 'display quality', 'versatile usage']\n",
      "  [3] sentiment='positive' score=0.85 key_themes=['meal preparation', 'convenience', 'time-saving']\n",
      "  [4] sentiment='mixed' score=0.6 key_themes=['seasonal versatility', 'temperature limitations', 'lightweight design']\n",
      "  [5] sentiment='positive' score=0.95 key_themes=['display quality', 'family satisfaction', 'product appeal']\n",
      "  [6] sentiment='positive' score=0.9 key_themes=['audio quality', 'portability', 'durability']\n",
      "  [7] sentiment='positive' score=0.92 key_themes=['health benefits', 'ergonomics', 'value proposition']\n",
      "  [8] sentiment='positive' score=0.88 key_themes=['quality', 'durability', 'cooking performance']\n",
      "  [9] sentiment='positive' score=0.89 key_themes=['reliability', 'innovation', 'practical functionality']\n",
      "\n",
      "Score validation:\n",
      "  [0] score=0.95 sentiment=positive valid=True themes=['sound quality', 'comfort', 'long-distance use']\n",
      "  [1] score=0.65 sentiment=mixed    valid=True themes=['performance on hardwood', 'battery life limitation']\n",
      "  [2] score=0.90 sentiment=positive valid=True themes=['portability', 'display quality', 'versatile usage']\n",
      "  [3] score=0.85 sentiment=positive valid=True themes=['meal preparation', 'convenience', 'time-saving']\n",
      "  [4] score=0.60 sentiment=mixed    valid=True themes=['seasonal versatility', 'temperature limitations', 'lightweight design']\n",
      "  [5] score=0.95 sentiment=positive valid=True themes=['display quality', 'family satisfaction', 'product appeal']\n",
      "  [6] score=0.90 sentiment=positive valid=True themes=['audio quality', 'portability', 'durability']\n",
      "  [7] score=0.92 sentiment=positive valid=True themes=['health benefits', 'ergonomics', 'value proposition']\n",
      "  [8] score=0.88 sentiment=positive valid=True themes=['quality', 'durability', 'cooking performance']\n",
      "  [9] score=0.89 sentiment=positive valid=True themes=['reliability', 'innovation', 'practical functionality']\n"
     ]
    }
   ],
   "source": [
    "model = Model(provider=\"anthropic\", name=\"claude-haiku-4-5-20251001\", api_key=ANTHROPIC_KEY, params={\"temperature\": 0})\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Analyze the sentiment of each product's customer_review. \"\n",
    "    \"Identify the overall sentiment, assign a score between 0.0 and 1.0, \"\n",
    "    \"and extract 1-3 key themes.\",\n",
    "    output_model=SentimentAnalysis,\n",
    "    batch_size=5,\n",
    "    concurrency=2,\n",
    "    stop_on_exhaustion=False,\n",
    ")\n",
    "\n",
    "result = await job.arun(model, data=products)\n",
    "show_result(\"Anthropic / claude-haiku-4.5 — Sentiment Analysis\", result)\n",
    "\n",
    "print(\"\\nScore validation:\")\n",
    "for i, row in enumerate(result.data):\n",
    "    in_range = 0.0 <= row.score <= 1.0\n",
    "    print(f\"  [{i}] score={row.score:.2f} sentiment={row.sentiment:8s} valid={in_range} themes={row.key_themes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "test2-gemini",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  Gemini / gemini-2.0-flash — Sentiment Analysis\n",
      "  Status: SUCCESS\n",
      "  Rows: 10/10 successful\n",
      "  Batches: 2/2 successful\n",
      "  Tokens: 1,283 in / 606 out\n",
      "  Retries: 0 | Time: 3.00s\n",
      "======================================================================\n",
      "\n",
      "  [0] sentiment='positive' score=0.9 key_themes=['sound quality', 'comfort']\n",
      "  [1] sentiment='mixed' score=0.6 key_themes=['hardwood', 'battery life']\n",
      "  [2] sentiment='positive' score=0.8 key_themes=['reading', 'beach', 'bed']\n",
      "  [3] sentiment='positive' score=0.7 key_themes=['meal prep', 'easy']\n",
      "  [4] sentiment='mixed' score=0.5 key_themes=['warmth', 'fall', 'winter']\n",
      "  [5] sentiment='positive' score=0.9 key_themes=['kids love it', 'gorgeous screen']\n",
      "  [6] sentiment='positive' score=0.85 key_themes=['poolside speaker', 'deep bass']\n",
      "  [7] sentiment='positive' score=0.9 key_themes=['back pain relief', 'ergonomic']\n",
      "  [8] sentiment='positive' score=0.8 key_themes=['heavy', 'worth the price', 'soups and braises']\n",
      "  [9] sentiment='positive' score=0.9 key_themes=['obstacle avoidance', \"doesn't eat socks\"]\n",
      "\n",
      "Score validation:\n",
      "  [0] score=0.90 sentiment=positive valid=True themes=['sound quality', 'comfort']\n",
      "  [1] score=0.60 sentiment=mixed    valid=True themes=['hardwood', 'battery life']\n",
      "  [2] score=0.80 sentiment=positive valid=True themes=['reading', 'beach', 'bed']\n",
      "  [3] score=0.70 sentiment=positive valid=True themes=['meal prep', 'easy']\n",
      "  [4] score=0.50 sentiment=mixed    valid=True themes=['warmth', 'fall', 'winter']\n",
      "  [5] score=0.90 sentiment=positive valid=True themes=['kids love it', 'gorgeous screen']\n",
      "  [6] score=0.85 sentiment=positive valid=True themes=['poolside speaker', 'deep bass']\n",
      "  [7] score=0.90 sentiment=positive valid=True themes=['back pain relief', 'ergonomic']\n",
      "  [8] score=0.80 sentiment=positive valid=True themes=['heavy', 'worth the price', 'soups and braises']\n",
      "  [9] score=0.90 sentiment=positive valid=True themes=['obstacle avoidance', \"doesn't eat socks\"]\n"
     ]
    }
   ],
   "source": [
    "model = Model(provider=\"google_genai\", name=\"gemini-2.0-flash\", api_key=GEMINI_KEY, params={\"temperature\": 0})\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Analyze the sentiment of each product's customer_review. \"\n",
    "    \"Identify the overall sentiment, assign a score between 0.0 and 1.0, \"\n",
    "    \"and extract 1-3 key themes.\",\n",
    "    output_model=SentimentAnalysis,\n",
    "    batch_size=5,\n",
    "    concurrency=2,\n",
    "    stop_on_exhaustion=False,\n",
    ")\n",
    "\n",
    "result = await job.arun(model, data=products)\n",
    "show_result(\"Gemini / gemini-2.0-flash — Sentiment Analysis\", result)\n",
    "\n",
    "print(\"\\nScore validation:\")\n",
    "for i, row in enumerate(result.data):\n",
    "    in_range = 0.0 <= row.score <= 1.0\n",
    "    print(f\"  [{i}] score={row.score:.2f} sentiment={row.sentiment:8s} valid={in_range} themes={row.key_themes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test3-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Support Ticket Triage — Complex Schema\n",
    "\n",
    "Tests Literal types, booleans, and longer text generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "test3-openai",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  OpenAI / gpt-4.1-mini — Ticket Triage\n",
      "  Status: SUCCESS\n",
      "  Rows: 10/10 successful\n",
      "  Batches: 2/2 successful\n",
      "  Tokens: 1,593 in / 506 out\n",
      "  Retries: 0 | Time: 3.55s\n",
      "======================================================================\n",
      "\n",
      "  [0] category='shipping' priority='urgent' requires_human=True suggested_response=\"We're sorry to hear your laptop arrived damaged. We'll expedite a replacement immediately. Our support team will contact you shortly for details.\"\n",
      "  [1] category='billing' priority='medium' requires_human=False suggested_response='To switch your subscription to annual billing, please follow the instructions in your account settings. Let us know if you need any further assistance.'\n",
      "  [2] category='technical' priority='high' requires_human=True suggested_response=\"We're sorry for the inconvenience caused by the software crashing. Our technical team will investigate and get back to you with a solution as soon as possible.\"\n",
      "  [3] category='billing' priority='high' requires_human=True suggested_response='We apologize for the double charge. Our billing team will review your order and issue a refund promptly. Thank you for your patience.'\n",
      "  [4] category='account' priority='medium' requires_human=False suggested_response=\"We can help you set up two-factor authentication. Please follow the guide in your account security settings or let us know if you'd like step-by-step assistance.\"\n",
      "  [5] category='shipping' priority='high' requires_human=True suggested_response=\"We're very sorry to hear your package was damaged due to being left in the rain. We will escalate this issue to our delivery team and arrange a replacement or refund for you promptly.\"\n",
      "  [6] category='general' priority='low' requires_human=False suggested_response='Thank you for your feedback! We apologize for the inconvenience. We will look into providing manuals in additional languages including English soon.'\n",
      "  [7] category='billing' priority='high' requires_human=True suggested_response=\"We have received your cancellation and refund request. We will process this as soon as possible and confirm once it's completed.\"\n",
      "  [8] category='shipping' priority='medium' requires_human=True suggested_response=\"We're sorry the item color didn't match your expectations. Please provide photos and we will assist you with a return or exchange.\"\n",
      "  [9] category='account' priority='medium' requires_human=True suggested_response='We will update your shipping address before your next order as requested. Please confirm the new address details.'\n",
      "\n",
      "Full triage results:\n",
      "\n",
      "  [0] TK-1001\n",
      "      Category: shipping | Priority: urgent | Human: True\n",
      "      Response: We're sorry to hear your laptop arrived damaged. We'll expedite a replacement immediately. Our suppo...\n",
      "\n",
      "  [1] TK-1002\n",
      "      Category: billing | Priority: medium | Human: False\n",
      "      Response: To switch your subscription to annual billing, please follow the instructions in your account settin...\n",
      "\n",
      "  [2] TK-1003\n",
      "      Category: technical | Priority: high | Human: True\n",
      "      Response: We're sorry for the inconvenience caused by the software crashing. Our technical team will investiga...\n",
      "\n",
      "  [3] TK-1004\n",
      "      Category: billing | Priority: high | Human: True\n",
      "      Response: We apologize for the double charge. Our billing team will review your order and issue a refund promp...\n",
      "\n",
      "  [4] TK-1005\n",
      "      Category: account | Priority: medium | Human: False\n",
      "      Response: We can help you set up two-factor authentication. Please follow the guide in your account security s...\n",
      "\n",
      "  [5] TK-1006\n",
      "      Category: shipping | Priority: high | Human: True\n",
      "      Response: We're very sorry to hear your package was damaged due to being left in the rain. We will escalate th...\n",
      "\n",
      "  [6] TK-1007\n",
      "      Category: general | Priority: low | Human: False\n",
      "      Response: Thank you for your feedback! We apologize for the inconvenience. We will look into providing manuals...\n",
      "\n",
      "  [7] TK-1008\n",
      "      Category: billing | Priority: high | Human: True\n",
      "      Response: We have received your cancellation and refund request. We will process this as soon as possible and ...\n",
      "\n",
      "  [8] TK-1009\n",
      "      Category: shipping | Priority: medium | Human: True\n",
      "      Response: We're sorry the item color didn't match your expectations. Please provide photos and we will assist ...\n",
      "\n",
      "  [9] TK-1010\n",
      "      Category: account | Priority: medium | Human: True\n",
      "      Response: We will update your shipping address before your next order as requested. Please confirm the new add...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeevanprakash/Desktop/work/cydratech/llm-data-transformation/.venv/lib/python3.10/site-packages/pydantic/main.py:464: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `none` - serialized value may not be as expected [field_name='parsed', input_value=_SmeltBatch(rows=[_SmeltT...s details.', row_id=9)]), input_type=_SmeltBatch])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "/Users/jeevanprakash/Desktop/work/cydratech/llm-data-transformation/.venv/lib/python3.10/site-packages/pydantic/main.py:464: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `none` - serialized value may not be as expected [field_name='parsed', input_value=_SmeltBatch(rows=[_SmeltT...ssistance.\", row_id=4)]), input_type=_SmeltBatch])\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    }
   ],
   "source": [
    "model = Model(provider=\"openai\", name=\"gpt-4.1-mini\", api_key=OPENAI_KEY)\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Triage each support ticket. Classify by category (billing, technical, \"\n",
    "    \"shipping, account, or general), assign priority, determine if human escalation \"\n",
    "    \"is needed, and write a brief suggested response.\",\n",
    "    output_model=TicketTriage,\n",
    "    batch_size=5,\n",
    "    concurrency=2,\n",
    "    stop_on_exhaustion=False,\n",
    ")\n",
    "\n",
    "result = await job.arun(model, data=tickets)\n",
    "show_result(\"OpenAI / gpt-4.1-mini — Ticket Triage\", result)\n",
    "\n",
    "print(\"\\nFull triage results:\")\n",
    "for i, row in enumerate(result.data):\n",
    "    print(f\"\\n  [{i}] {tickets[i]['ticket_id']}\")\n",
    "    print(f\"      Category: {row.category} | Priority: {row.priority} | Human: {row.requires_human}\")\n",
    "    print(f\"      Response: {row.suggested_response[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "test3-anthropic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  Anthropic / claude-sonnet-4 — Ticket Triage\n",
      "  Status: SUCCESS\n",
      "  Rows: 10/10 successful\n",
      "  Batches: 2/2 successful\n",
      "  Tokens: 2,407 in / 964 out\n",
      "  Retries: 0 | Time: 8.50s\n",
      "======================================================================\n",
      "\n",
      "  [0] category='shipping' priority='high' requires_human=True suggested_response=\"I apologize for the damaged laptop. I'll immediately arrange a replacement shipment and provide a return label for the damaged unit. You should receive your replacement within 1-2 business days.\"\n",
      "  [1] category='billing' priority='low' requires_human=False suggested_response=\"I can help you switch to annual billing! You can change this in your account settings under 'Billing Preferences' or I can process this change for you right now. Annual billing also includes a 15% discount.\"\n",
      "  [2] category='technical' priority='medium' requires_human=False suggested_response=\"I'm sorry you're experiencing crashes with PDF export. Let's troubleshoot this - please try updating to the latest version first. If the issue persists, I'll need some system details to help resolve this quickly.\"\n",
      "  [3] category='billing' priority='high' requires_human=True suggested_response=\"I see the duplicate charge on your account from last week. I'll immediately process a refund for the duplicate transaction. You should see the refund within 3-5 business days, and I'll send you a confirmation email.\"\n",
      "  [4] category='account' priority='medium' requires_human=False suggested_response=\"I'd be happy to help you set up two-factor authentication! I'll walk you through the process step-by-step. First, go to your Account Settings and click on 'Security.' Do you have a mobile device ready for the setup?\"\n",
      "  [5] category='shipping' priority='high' requires_human=True suggested_response=\"I sincerely apologize for the damaged delivery. We'll send you a replacement Smart Home Kit immediately and escalate this delivery issue with our shipping partner to prevent future incidents.\"\n",
      "  [6] category='general' priority='low' requires_human=False suggested_response=\"Thank you for your feedback! I'll send you the English manual for your Robot Vacuum R5 via email right away. We appreciate you bringing this to our attention.\"\n",
      "  [7] category='billing' priority='medium' requires_human=False suggested_response='I can help you cancel your Premium Music Stream subscription and process your refund for this month. Let me get that started for you right away.'\n",
      "  [8] category='general' priority='medium' requires_human=False suggested_response='I apologize for the color mismatch with your Ergonomic Chair V2. I can arrange a return/exchange or provide a partial refund to resolve this issue to your satisfaction.'\n",
      "  [9] category='account' priority='medium' requires_human=False suggested_response=\"I'll update your shipping address right away to ensure your next Monthly Snack Box is delivered to the correct location. Please provide your new address details.\"\n",
      "\n",
      "Full triage results:\n",
      "\n",
      "  [0] TK-1001\n",
      "      Category: shipping | Priority: high | Human: True\n",
      "      Response: I apologize for the damaged laptop. I'll immediately arrange a replacement shipment and provide a re...\n",
      "\n",
      "  [1] TK-1002\n",
      "      Category: billing | Priority: low | Human: False\n",
      "      Response: I can help you switch to annual billing! You can change this in your account settings under 'Billing...\n",
      "\n",
      "  [2] TK-1003\n",
      "      Category: technical | Priority: medium | Human: False\n",
      "      Response: I'm sorry you're experiencing crashes with PDF export. Let's troubleshoot this - please try updating...\n",
      "\n",
      "  [3] TK-1004\n",
      "      Category: billing | Priority: high | Human: True\n",
      "      Response: I see the duplicate charge on your account from last week. I'll immediately process a refund for the...\n",
      "\n",
      "  [4] TK-1005\n",
      "      Category: account | Priority: medium | Human: False\n",
      "      Response: I'd be happy to help you set up two-factor authentication! I'll walk you through the process step-by...\n",
      "\n",
      "  [5] TK-1006\n",
      "      Category: shipping | Priority: high | Human: True\n",
      "      Response: I sincerely apologize for the damaged delivery. We'll send you a replacement Smart Home Kit immediat...\n",
      "\n",
      "  [6] TK-1007\n",
      "      Category: general | Priority: low | Human: False\n",
      "      Response: Thank you for your feedback! I'll send you the English manual for your Robot Vacuum R5 via email rig...\n",
      "\n",
      "  [7] TK-1008\n",
      "      Category: billing | Priority: medium | Human: False\n",
      "      Response: I can help you cancel your Premium Music Stream subscription and process your refund for this month....\n",
      "\n",
      "  [8] TK-1009\n",
      "      Category: general | Priority: medium | Human: False\n",
      "      Response: I apologize for the color mismatch with your Ergonomic Chair V2. I can arrange a return/exchange or ...\n",
      "\n",
      "  [9] TK-1010\n",
      "      Category: account | Priority: medium | Human: False\n",
      "      Response: I'll update your shipping address right away to ensure your next Monthly Snack Box is delivered to t...\n"
     ]
    }
   ],
   "source": [
    "model = Model(provider=\"anthropic\", name=\"claude-sonnet-4-20250514\", api_key=ANTHROPIC_KEY)\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Triage each support ticket. Classify by category (billing, technical, \"\n",
    "    \"shipping, account, or general), assign priority, determine if human escalation \"\n",
    "    \"is needed, and write a brief suggested response.\",\n",
    "    output_model=TicketTriage,\n",
    "    batch_size=5,\n",
    "    concurrency=2,\n",
    "    stop_on_exhaustion=False,\n",
    ")\n",
    "\n",
    "result = await job.arun(model, data=tickets)\n",
    "show_result(\"Anthropic / claude-sonnet-4 — Ticket Triage\", result)\n",
    "\n",
    "print(\"\\nFull triage results:\")\n",
    "for i, row in enumerate(result.data):\n",
    "    print(f\"\\n  [{i}] {tickets[i]['ticket_id']}\")\n",
    "    print(f\"      Category: {row.category} | Priority: {row.priority} | Human: {row.requires_human}\")\n",
    "    print(f\"      Response: {row.suggested_response[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "test3-gemini",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  Gemini / gemini-2.5-flash — Ticket Triage\n",
      "  Status: SUCCESS\n",
      "  Rows: 10/10 successful\n",
      "  Batches: 2/2 successful\n",
      "  Tokens: 1,407 in / 2,302 out\n",
      "  Retries: 0 | Time: 7.67s\n",
      "======================================================================\n",
      "\n",
      "  [0] category='shipping' priority='urgent' requires_human=True suggested_response='We apologize for the damaged item. We will arrange for a replacement to be sent to you immediately. Please provide details.'\n",
      "  [1] category='billing' priority='low' requires_human=False suggested_response=\"You can change your subscription billing cycle from monthly to annual in your account settings under the 'Subscription' or 'Billing' section.\"\n",
      "  [2] category='technical' priority='high' requires_human=True suggested_response='We apologize for the software crashing. Please provide more details about your operating system and software version so our technical team can assist.'\n",
      "  [3] category='billing' priority='urgent' requires_human=True suggested_response='We apologize for the duplicate charge. We are investigating this immediately and will process a refund if an error is confirmed.'\n",
      "  [4] category='account' priority='medium' requires_human=False suggested_response='To set up two-factor authentication, please navigate to your account security settings and follow the prompts to enable 2FA.'\n",
      "  [5] category='shipping' priority='high' requires_human=True suggested_response='We apologize for the damaged package. We will arrange for a replacement or refund immediately. A human agent will contact you shortly.'\n",
      "  [6] category='technical' priority='medium' requires_human=False suggested_response='We apologize for the incorrect manual. Please find the link to the English version of the manual here: [Link to Manual]'\n",
      "  [7] category='billing' priority='high' requires_human=True suggested_response='Your subscription cancellation and refund request have been received. A human agent will process this and confirm details with you shortly.'\n",
      "  [8] category='shipping' priority='high' requires_human=True suggested_response=\"We apologize that the item's color does not match the website. We can arrange for a return and exchange or refund. A human agent will contact you to assist.\"\n",
      "  [9] category='account' priority='high' requires_human=True suggested_response='Your request to update the shipping address has been received. We will ensure this is applied before your next order ships. A human agent will confirm the update.'\n",
      "\n",
      "Full triage results:\n",
      "\n",
      "  [0] TK-1001\n",
      "      Category: shipping | Priority: urgent | Human: True\n",
      "      Response: We apologize for the damaged item. We will arrange for a replacement to be sent to you immediately. ...\n",
      "\n",
      "  [1] TK-1002\n",
      "      Category: billing | Priority: low | Human: False\n",
      "      Response: You can change your subscription billing cycle from monthly to annual in your account settings under...\n",
      "\n",
      "  [2] TK-1003\n",
      "      Category: technical | Priority: high | Human: True\n",
      "      Response: We apologize for the software crashing. Please provide more details about your operating system and ...\n",
      "\n",
      "  [3] TK-1004\n",
      "      Category: billing | Priority: urgent | Human: True\n",
      "      Response: We apologize for the duplicate charge. We are investigating this immediately and will process a refu...\n",
      "\n",
      "  [4] TK-1005\n",
      "      Category: account | Priority: medium | Human: False\n",
      "      Response: To set up two-factor authentication, please navigate to your account security settings and follow th...\n",
      "\n",
      "  [5] TK-1006\n",
      "      Category: shipping | Priority: high | Human: True\n",
      "      Response: We apologize for the damaged package. We will arrange for a replacement or refund immediately. A hum...\n",
      "\n",
      "  [6] TK-1007\n",
      "      Category: technical | Priority: medium | Human: False\n",
      "      Response: We apologize for the incorrect manual. Please find the link to the English version of the manual her...\n",
      "\n",
      "  [7] TK-1008\n",
      "      Category: billing | Priority: high | Human: True\n",
      "      Response: Your subscription cancellation and refund request have been received. A human agent will process thi...\n",
      "\n",
      "  [8] TK-1009\n",
      "      Category: shipping | Priority: high | Human: True\n",
      "      Response: We apologize that the item's color does not match the website. We can arrange for a return and excha...\n",
      "\n",
      "  [9] TK-1010\n",
      "      Category: account | Priority: high | Human: True\n",
      "      Response: Your request to update the shipping address has been received. We will ensure this is applied before...\n"
     ]
    }
   ],
   "source": [
    "model = Model(provider=\"google_genai\", name=\"gemini-2.5-flash\", api_key=GEMINI_KEY)\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Triage each support ticket. Classify by category (billing, technical, \"\n",
    "    \"shipping, account, or general), assign priority, determine if human escalation \"\n",
    "    \"is needed, and write a brief suggested response.\",\n",
    "    output_model=TicketTriage,\n",
    "    batch_size=5,\n",
    "    concurrency=2,\n",
    "    stop_on_exhaustion=False,\n",
    ")\n",
    "\n",
    "result = await job.arun(model, data=tickets)\n",
    "show_result(\"Gemini / gemini-2.5-flash — Ticket Triage\", result)\n",
    "\n",
    "print(\"\\nFull triage results:\")\n",
    "for i, row in enumerate(result.data):\n",
    "    print(f\"\\n  [{i}] {tickets[i]['ticket_id']}\")\n",
    "    print(f\"      Category: {row.category} | Priority: {row.priority} | Human: {row.requires_human}\")\n",
    "    print(f\"      Response: {row.suggested_response[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test4-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Parameter Tuning — Temperature Comparison\n",
    "\n",
    "Compare temperature=0 (deterministic) vs temperature=1.0 (creative) on the same task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "test4-temp",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeevanprakash/Desktop/work/cydratech/llm-data-transformation/.venv/lib/python3.10/site-packages/pydantic/main.py:464: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `none` - serialized value may not be as expected [field_name='parsed', input_value=_SmeltBatch(rows=[_SmeltI...public=True, row_id=2)]), input_type=_SmeltBatch])\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  OpenAI / gpt-4.1-mini — temp=0\n",
      "  Status: SUCCESS\n",
      "  Rows: 3/3 successful\n",
      "  Batches: 1/1 successful\n",
      "  Tokens: 535 in / 74 out\n",
      "  Retries: 0 | Time: 1.49s\n",
      "======================================================================\n",
      "\n",
      "  [0] sector='Technology' sub_sector='Consumer Electronics and Software' is_public=True\n",
      "  [1] sector='Financial Services' sub_sector='Investment Banking and Financial Services' is_public=True\n",
      "  [2] sector='Healthcare' sub_sector='Pharmaceuticals and Biotechnology' is_public=True\n",
      "\n",
      "======================================================================\n",
      "  OpenAI / gpt-4.1-mini — temp=0.5\n",
      "  Status: SUCCESS\n",
      "  Rows: 3/3 successful\n",
      "  Batches: 1/1 successful\n",
      "  Tokens: 535 in / 74 out\n",
      "  Retries: 0 | Time: 1.94s\n",
      "======================================================================\n",
      "\n",
      "  [0] sector='Technology' sub_sector='Consumer Electronics and Software' is_public=True\n",
      "  [1] sector='Financial Services' sub_sector='Investment Banking and Financial Services' is_public=True\n",
      "  [2] sector='Healthcare' sub_sector='Pharmaceuticals and Biotechnology' is_public=True\n",
      "\n",
      "======================================================================\n",
      "  OpenAI / gpt-4.1-mini — temp=1.0\n",
      "  Status: SUCCESS\n",
      "  Rows: 3/3 successful\n",
      "  Batches: 1/1 successful\n",
      "  Tokens: 535 in / 67 out\n",
      "  Retries: 0 | Time: 1.46s\n",
      "======================================================================\n",
      "\n",
      "  [0] sector='Technology' sub_sector='Consumer Electronics' is_public=True\n",
      "  [1] sector='Financial Services' sub_sector='Investment Banking' is_public=True\n",
      "  [2] sector='Healthcare' sub_sector='Pharmaceuticals' is_public=True\n"
     ]
    }
   ],
   "source": [
    "data_subset = companies[:3]\n",
    "\n",
    "for temp in [0, 0.5, 1.0]:\n",
    "    model = Model(\n",
    "        provider=\"openai\", name=\"gpt-4.1-mini\", api_key=OPENAI_KEY,\n",
    "        params={\"temperature\": temp},\n",
    "    )\n",
    "    job = Job(\n",
    "        prompt=\"Classify each company by industry sector.\",\n",
    "        output_model=IndustryClassification,\n",
    "        batch_size=10,\n",
    "        stop_on_exhaustion=False,\n",
    "    )\n",
    "    result = await job.arun(model, data=data_subset)\n",
    "    show_result(f\"OpenAI / gpt-4.1-mini — temp={temp}\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test4-top-p",
   "metadata": {},
   "outputs": [],
   "source": "# Anthropic: top_p (mutually exclusive with temperature) and top_k\n# NOTE: Anthropic does NOT allow setting both temperature and top_p simultaneously.\nfor top_p in [0.5, 0.9]:\n    model = Model(\n        provider=\"anthropic\", name=\"claude-haiku-4-5-20251001\", api_key=ANTHROPIC_KEY,\n        params={\"top_p\": top_p, \"top_k\": 40},\n    )\n    job = Job(\n        prompt=\"Classify each company by industry sector.\",\n        output_model=IndustryClassification,\n        batch_size=10,\n        stop_on_exhaustion=False,\n    )\n    result = await job.arun(model, data=data_subset)\n    show_result(f\"Anthropic / claude-haiku-4.5 — top_p={top_p}, top_k=40\", result)"
  },
  {
   "cell_type": "markdown",
   "id": "test5-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Batch Configuration — Size & Concurrency\n",
    "\n",
    "Compare different batch_size and concurrency settings on the same dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "test5-batch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  Config: 1 batch, serial (batch=10, conc=1)\n",
      "  Status: SUCCESS\n",
      "  Rows: 10/10 successful\n",
      "  Batches: 1/1 successful\n",
      "  Tokens: 948 in / 223 out\n",
      "  Retries: 0 | Time: 5.17s\n",
      "======================================================================\n",
      "\n",
      "  [0] sector='Technology' sub_sector='Consumer Electronics' is_public=True\n",
      "  [1] sector='Financial Services' sub_sector='Banking and Investment' is_public=True\n",
      "  [2] sector='Healthcare' sub_sector='Pharmaceuticals and Biotechnology' is_public=True\n",
      "  [3] sector='Automotive' sub_sector='Electric Vehicles and Clean Energy' is_public=True\n",
      "  [4] sector='Media and Entertainment' sub_sector='Streaming Services' is_public=True\n",
      "  [5] sector='Professional Services' sub_sector='Audit and Consulting' is_public=False\n",
      "  [6] sector='Media and Entertainment' sub_sector='Digital Music Streaming' is_public=True\n",
      "  [7] sector='Financial Services' sub_sector='Financial Technology' is_public=False\n",
      "  [8] sector='Healthcare' sub_sector='Biotechnology' is_public=True\n",
      "  [9] sector='Technology' sub_sector='Online Marketplace' is_public=True\n",
      "  ... and 7 more rows\n",
      "  Row ordering verified: 10 rows in correct order\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeevanprakash/Desktop/work/cydratech/llm-data-transformation/.venv/lib/python3.10/site-packages/pydantic/main.py:464: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `none` - serialized value may not be as expected [field_name='parsed', input_value=_SmeltBatch(rows=[_SmeltI...public=True, row_id=4)]), input_type=_SmeltBatch])\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  Config: 2 batches, conc=2 (batch=5, conc=2)\n",
      "  Status: SUCCESS\n",
      "  Rows: 10/10 successful\n",
      "  Batches: 2/2 successful\n",
      "  Tokens: 1,300 in / 232 out\n",
      "  Retries: 0 | Time: 2.98s\n",
      "======================================================================\n",
      "\n",
      "  [0] sector='Technology' sub_sector='Consumer Electronics and Software' is_public=True\n",
      "  [1] sector='Financial Services' sub_sector='Investment Banking and Financial Services' is_public=True\n",
      "  [2] sector='Healthcare' sub_sector='Pharmaceuticals and Biotechnology' is_public=True\n",
      "  [3] sector='Automotive and Energy' sub_sector='Electric Vehicles and Clean Energy' is_public=True\n",
      "  [4] sector='Media and Entertainment' sub_sector='Streaming Services' is_public=True\n",
      "  [5] sector='Professional Services' sub_sector='Consulting and Audit' is_public=False\n",
      "  [6] sector='Technology' sub_sector='Digital Media Streaming' is_public=True\n",
      "  [7] sector='Financial Services' sub_sector='Payment Processing' is_public=False\n",
      "  [8] sector='Healthcare' sub_sector='Biotechnology' is_public=True\n",
      "  [9] sector='Technology' sub_sector='Online Marketplace' is_public=True\n",
      "  ... and 7 more rows\n",
      "  Row ordering verified: 10 rows in correct order\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeevanprakash/Desktop/work/cydratech/llm-data-transformation/.venv/lib/python3.10/site-packages/pydantic/main.py:464: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `none` - serialized value may not be as expected [field_name='parsed', input_value=_SmeltBatch(rows=[_SmeltI...public=True, row_id=3)]), input_type=_SmeltBatch])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "/Users/jeevanprakash/Desktop/work/cydratech/llm-data-transformation/.venv/lib/python3.10/site-packages/pydantic/main.py:464: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `none` - serialized value may not be as expected [field_name='parsed', input_value=_SmeltBatch(rows=[_SmeltI...public=True, row_id=1)]), input_type=_SmeltBatch])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "/Users/jeevanprakash/Desktop/work/cydratech/llm-data-transformation/.venv/lib/python3.10/site-packages/pydantic/main.py:464: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `none` - serialized value may not be as expected [field_name='parsed', input_value=_SmeltBatch(rows=[_SmeltI...ublic=False, row_id=5)]), input_type=_SmeltBatch])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "/Users/jeevanprakash/Desktop/work/cydratech/llm-data-transformation/.venv/lib/python3.10/site-packages/pydantic/main.py:464: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `none` - serialized value may not be as expected [field_name='parsed', input_value=_SmeltBatch(rows=[_SmeltI...ublic=False, row_id=7)]), input_type=_SmeltBatch])\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  Config: 5 batches, conc=5 (batch=2, conc=5)\n",
      "  Status: SUCCESS\n",
      "  Rows: 10/10 successful\n",
      "  Batches: 5/5 successful\n",
      "  Tokens: 2,356 in / 245 out\n",
      "  Retries: 0 | Time: 2.03s\n",
      "======================================================================\n",
      "\n",
      "  [0] sector='Technology' sub_sector='Consumer Electronics and Software' is_public=True\n",
      "  [1] sector='Financial Services' sub_sector='Investment Banking and Financial Services' is_public=True\n",
      "  [2] sector='Healthcare' sub_sector='Pharmaceuticals & Biotechnology' is_public=True\n",
      "  [3] sector='Automotive' sub_sector='Electric Vehicles & Clean Energy' is_public=True\n",
      "  [4] sector='Media & Entertainment' sub_sector='Streaming Services' is_public=True\n",
      "  [5] sector='Professional Services' sub_sector='Audit and Consulting' is_public=False\n",
      "  [6] sector='Technology' sub_sector='Digital Media Streaming' is_public=True\n",
      "  [7] sector='Financial Services' sub_sector='Payment Processing' is_public=False\n",
      "  [8] sector='Healthcare' sub_sector='Biotechnology' is_public=True\n",
      "  [9] sector='Consumer Services' sub_sector='Online Marketplace' is_public=True\n",
      "  ... and 7 more rows\n",
      "  Row ordering verified: 10 rows in correct order\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeevanprakash/Desktop/work/cydratech/llm-data-transformation/.venv/lib/python3.10/site-packages/pydantic/main.py:464: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `none` - serialized value may not be as expected [field_name='parsed', input_value=_SmeltBatch(rows=[_SmeltI...public=True, row_id=0)]), input_type=_SmeltBatch])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "/Users/jeevanprakash/Desktop/work/cydratech/llm-data-transformation/.venv/lib/python3.10/site-packages/pydantic/main.py:464: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `none` - serialized value may not be as expected [field_name='parsed', input_value=_SmeltBatch(rows=[_SmeltI...public=True, row_id=6)]), input_type=_SmeltBatch])\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  Config: 10 batches, conc=10 (batch=1, conc=10)\n",
      "  Status: SUCCESS\n",
      "  Rows: 10/10 successful\n",
      "  Batches: 10/10 successful\n",
      "  Tokens: 4,116 in / 263 out\n",
      "  Retries: 0 | Time: 1.97s\n",
      "======================================================================\n",
      "\n",
      "  [0] sector='Technology' sub_sector='Consumer Electronics' is_public=True\n",
      "  [1] sector='Financial Services' sub_sector='Banking' is_public=True\n",
      "  [2] sector='Healthcare' sub_sector='Pharmaceuticals & Biotechnology' is_public=True\n",
      "  [3] sector='Automotive' sub_sector='Electric Vehicles' is_public=True\n",
      "  [4] sector='Technology' sub_sector='Streaming Entertainment' is_public=True\n",
      "  [5] sector='Professional Services' sub_sector='Audit and Consulting' is_public=False\n",
      "  [6] sector='Technology' sub_sector='Digital Media Streaming' is_public=True\n",
      "  [7] sector='Financial Services' sub_sector='Payment Processing' is_public=False\n",
      "  [8] sector='Healthcare' sub_sector='Biotechnology' is_public=True\n",
      "  [9] sector='Consumer Services' sub_sector='Online Travel and Lodging' is_public=True\n",
      "  ... and 7 more rows\n",
      "  Row ordering verified: 10 rows in correct order\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeevanprakash/Desktop/work/cydratech/llm-data-transformation/.venv/lib/python3.10/site-packages/pydantic/main.py:464: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `none` - serialized value may not be as expected [field_name='parsed', input_value=_SmeltBatch(rows=[_SmeltI...public=True, row_id=8)]), input_type=_SmeltBatch])\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    }
   ],
   "source": [
    "configs = [\n",
    "    {\"batch_size\": 10, \"concurrency\": 1, \"label\": \"1 batch, serial\"},\n",
    "    {\"batch_size\": 5, \"concurrency\": 2, \"label\": \"2 batches, conc=2\"},\n",
    "    {\"batch_size\": 2, \"concurrency\": 5, \"label\": \"5 batches, conc=5\"},\n",
    "    {\"batch_size\": 1, \"concurrency\": 10, \"label\": \"10 batches, conc=10\"},\n",
    "]\n",
    "\n",
    "model = Model(provider=\"openai\", name=\"gpt-4.1-mini\", api_key=OPENAI_KEY, params={\"temperature\": 0})\n",
    "\n",
    "for cfg in configs:\n",
    "    job = Job(\n",
    "        prompt=\"Classify each company by industry sector.\",\n",
    "        output_model=IndustryClassification,\n",
    "        batch_size=cfg[\"batch_size\"],\n",
    "        concurrency=cfg[\"concurrency\"],\n",
    "        stop_on_exhaustion=False,\n",
    "    )\n",
    "    result = await job.arun(model, data=companies)\n",
    "    show_result(f\"Config: {cfg['label']} (batch={cfg['batch_size']}, conc={cfg['concurrency']})\", result)\n",
    "    \n",
    "    # Verify all rows present and in order\n",
    "    assert len(result.data) == len(companies), f\"Row count mismatch: {len(result.data)} vs {len(companies)}\"\n",
    "    print(f\"  Row ordering verified: {len(result.data)} rows in correct order\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test6-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Error Handling — stop_on_exhaustion\n",
    "\n",
    "Demonstrate graceful error handling when `stop_on_exhaustion=False` collects errors,\n",
    "and when `stop_on_exhaustion=True` raises `SmeltExhaustionError` with partial results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "test6-collect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  Company Summary (stop_on_exhaustion=False)\n",
      "  Status: SUCCESS\n",
      "  Rows: 10/10 successful\n",
      "  Batches: 2/2 successful\n",
      "  Tokens: 1,430 in / 373 out\n",
      "  Retries: 0 | Time: 3.92s\n",
      "======================================================================\n",
      "\n",
      "  [0] one_liner='Apple Inc. designs and manufactures consumer electronics and software.' industry='Consumer Electronics' company_size='enterprise' age_years=50\n",
      "  [1] one_liner='JPMorgan Chase is a multinational investment bank and financial services company.' industry='Financial Services' company_size='enterprise' age_years=227\n",
      "  [2] one_liner='Pfizer is a global pharmaceutical and biotechnology corporation.' industry='Pharmaceuticals' company_size='enterprise' age_years=177\n",
      "  [3] one_liner='Tesla Inc. is an electric vehicle and clean energy company.' industry='Automotive' company_size='enterprise' age_years=23\n",
      "  [4] one_liner='Netflix is a streaming entertainment service provider.' industry='Entertainment' company_size='medium' age_years=29\n",
      "  [5] one_liner='Deloitte is a professional services network providing audit and consulting.' industry='Professional Services' company_size='enterprise' age_years=181\n",
      "  [6] one_liner='Spotify is a digital music and podcast streaming platform.' industry='Digital Media' company_size='large' age_years=20\n",
      "  [7] one_liner='Stripe is a financial infrastructure platform for internet businesses.' industry='Financial Technology' company_size='large' age_years=16\n",
      "  [8] one_liner='Moderna is a biotechnology company focused on mRNA therapeutics.' industry='Biotechnology' company_size='large' age_years=16\n",
      "  [9] one_liner='Airbnb is an online marketplace for short-term lodging and experiences.' industry='Hospitality' company_size='large' age_years=18\n",
      "  ... and 7 more rows\n",
      "\n",
      "success property: True\n",
      "result.data has 10 rows\n",
      "result.errors has 0 errors\n",
      "result.metrics: SmeltMetrics(total_rows=10, successful_rows=10, failed_rows=0, total_batches=2, successful_batches=2, failed_batches=0, total_retries=0, input_tokens=1430, output_tokens=373, wall_time_seconds=3.921)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeevanprakash/Desktop/work/cydratech/llm-data-transformation/.venv/lib/python3.10/site-packages/pydantic/main.py:464: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `none` - serialized value may not be as expected [field_name='parsed', input_value=_SmeltBatch(rows=[_SmeltC...ge_years=29, row_id=4)]), input_type=_SmeltBatch])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "/Users/jeevanprakash/Desktop/work/cydratech/llm-data-transformation/.venv/lib/python3.10/site-packages/pydantic/main.py:464: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `none` - serialized value may not be as expected [field_name='parsed', input_value=_SmeltBatch(rows=[_SmeltC...ge_years=18, row_id=9)]), input_type=_SmeltBatch])\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    }
   ],
   "source": [
    "# stop_on_exhaustion=False: errors are collected, successful batches still returned\n",
    "model = Model(provider=\"openai\", name=\"gpt-4.1-mini\", api_key=OPENAI_KEY, params={\"temperature\": 0})\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Create a concise structured summary for each company. \"\n",
    "    \"Calculate age based on founded year (current year is 2026).\",\n",
    "    output_model=CompanySummary,\n",
    "    batch_size=5,\n",
    "    concurrency=2,\n",
    "    max_retries=2,\n",
    "    stop_on_exhaustion=False,  # collect errors, don't raise\n",
    ")\n",
    "\n",
    "result = await job.arun(model, data=companies)\n",
    "show_result(\"Company Summary (stop_on_exhaustion=False)\", result)\n",
    "\n",
    "print(f\"\\nsuccess property: {result.success}\")\n",
    "print(f\"result.data has {len(result.data)} rows\")\n",
    "print(f\"result.errors has {len(result.errors)} errors\")\n",
    "print(f\"result.metrics: {result.metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "test6-exhaustion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  Classification (stop_on_exhaustion=True, no error expected)\n",
      "  Status: SUCCESS\n",
      "  Rows: 10/10 successful\n",
      "  Batches: 1/1 successful\n",
      "  Tokens: 948 in / 225 out\n",
      "  Retries: 0 | Time: 3.55s\n",
      "======================================================================\n",
      "\n",
      "  [0] sector='Technology' sub_sector='Consumer Electronics' is_public=True\n",
      "  [1] sector='Financial Services' sub_sector='Banking and Investment' is_public=True\n",
      "  [2] sector='Healthcare' sub_sector='Pharmaceuticals and Biotechnology' is_public=True\n",
      "  [3] sector='Automotive and Energy' sub_sector='Electric Vehicles and Clean Energy' is_public=True\n",
      "  [4] sector='Media and Entertainment' sub_sector='Streaming Services' is_public=True\n",
      "  [5] sector='Professional Services' sub_sector='Audit and Consulting' is_public=False\n",
      "  [6] sector='Media and Entertainment' sub_sector='Digital Music Streaming' is_public=True\n",
      "  [7] sector='Financial Services' sub_sector='Financial Technology' is_public=False\n",
      "  [8] sector='Healthcare' sub_sector='Biotechnology' is_public=True\n",
      "  [9] sector='Technology' sub_sector='Online Marketplace' is_public=True\n",
      "  ... and 7 more rows\n",
      "No exception raised — all batches succeeded.\n"
     ]
    }
   ],
   "source": [
    "# stop_on_exhaustion=True with a valid request — should succeed without raising\n",
    "model = Model(provider=\"openai\", name=\"gpt-4.1-mini\", api_key=OPENAI_KEY, params={\"temperature\": 0})\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Classify each company by industry sector.\",\n",
    "    output_model=IndustryClassification,\n",
    "    batch_size=10,\n",
    "    max_retries=3,\n",
    "    stop_on_exhaustion=True,  # will raise on failure\n",
    ")\n",
    "\n",
    "try:\n",
    "    result = await job.arun(model, data=companies)\n",
    "    show_result(\"Classification (stop_on_exhaustion=True, no error expected)\", result)\n",
    "    print(\"No exception raised — all batches succeeded.\")\n",
    "except SmeltExhaustionError as e:\n",
    "    print(f\"SmeltExhaustionError: {e}\")\n",
    "    print(f\"Partial results: {len(e.partial_result.data)} rows succeeded\")\n",
    "    print(f\"Errors: {len(e.partial_result.errors)} batches failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test7-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Async Execution\n",
    "\n",
    "Use `await job.arun()` directly (works in Jupyter notebooks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "test7-async-openai",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  OpenAI / gpt-4.1-mini — Async (batch=3, conc=4)\n",
      "  Status: SUCCESS\n",
      "  Rows: 10/10 successful\n",
      "  Batches: 4/4 successful\n",
      "  Tokens: 2,004 in / 244 out\n",
      "  Retries: 0 | Time: 2.84s\n",
      "======================================================================\n",
      "\n",
      "  [0] sector='Technology' sub_sector='Consumer Electronics and Software' is_public=True\n",
      "  [1] sector='Financial Services' sub_sector='Investment Banking and Financial Services' is_public=True\n",
      "  [2] sector='Healthcare' sub_sector='Pharmaceuticals and Biotechnology' is_public=True\n",
      "  [3] sector='Automotive' sub_sector='Electric Vehicles' is_public=True\n",
      "  [4] sector='Media & Entertainment' sub_sector='Streaming Services' is_public=True\n",
      "  [5] sector='Professional Services' sub_sector='Audit and Consulting' is_public=False\n",
      "  [6] sector='Technology' sub_sector='Digital Media Streaming' is_public=True\n",
      "  [7] sector='Financial Services' sub_sector='Financial Technology (FinTech)' is_public=False\n",
      "  [8] sector='Healthcare' sub_sector='Biotechnology' is_public=True\n",
      "  [9] sector='Consumer Services' sub_sector='Online Travel and Lodging' is_public=True\n",
      "  ... and 7 more rows\n",
      "  Batches: 4 (ceil(10/3) = 4)\n"
     ]
    }
   ],
   "source": [
    "model = Model(provider=\"openai\", name=\"gpt-4.1-mini\", api_key=OPENAI_KEY, params={\"temperature\": 0})\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Classify each company by industry sector.\",\n",
    "    output_model=IndustryClassification,\n",
    "    batch_size=3,\n",
    "    concurrency=4,\n",
    "    stop_on_exhaustion=False,\n",
    ")\n",
    "\n",
    "result = await job.arun(model, data=companies)\n",
    "show_result(\"OpenAI / gpt-4.1-mini — Async (batch=3, conc=4)\", result)\n",
    "print(f\"  Batches: {result.metrics.total_batches} (ceil(10/3) = 4)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "test7-async-anthropic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  Anthropic / claude-haiku-4.5 — Async Sentiment\n",
      "  Status: SUCCESS\n",
      "  Rows: 10/10 successful\n",
      "  Batches: 2/2 successful\n",
      "  Tokens: 2,847 in / 583 out\n",
      "  Retries: 0 | Time: 2.72s\n",
      "======================================================================\n",
      "\n",
      "  [0] sentiment='positive' score=0.95 key_themes=['sound quality', 'comfort', 'long-duration use']\n",
      "  [1] sentiment='mixed' score=0.65 key_themes=['performance on hardwood', 'battery life limitation']\n",
      "  [2] sentiment='positive' score=0.9 key_themes=['reading experience', 'versatile use cases']\n",
      "  [3] sentiment='positive' score=0.85 key_themes=['convenience', 'meal preparation', 'time-saving']\n",
      "  [4] sentiment='mixed' score=0.7 key_themes=['warmth for fall', 'seasonal limitation', 'material quality']\n",
      "  [5] sentiment='positive' score=0.9 key_themes=['Kids satisfaction', 'Display quality']\n",
      "  [6] sentiment='positive' score=0.85 key_themes=['Audio quality', 'Portability']\n",
      "  [7] sentiment='positive' score=0.95 key_themes=['Health benefits', 'Quality improvement']\n",
      "  [8] sentiment='positive' score=0.85 key_themes=['Value for money', 'Durability']\n",
      "  [9] sentiment='positive' score=0.88 key_themes=['Reliability', 'Convenience']\n",
      "  ... and 7 more rows\n"
     ]
    }
   ],
   "source": [
    "model = Model(provider=\"anthropic\", name=\"claude-haiku-4-5-20251001\", api_key=ANTHROPIC_KEY)\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Analyze the sentiment of each product review.\",\n",
    "    output_model=SentimentAnalysis,\n",
    "    batch_size=5,\n",
    "    concurrency=2,\n",
    "    stop_on_exhaustion=False,\n",
    ")\n",
    "\n",
    "result = await job.arun(model, data=products)\n",
    "show_result(\"Anthropic / claude-haiku-4.5 — Async Sentiment\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "test7-async-gemini",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  Gemini / gemini-2.5-flash — Async Ticket Triage\n",
      "  Status: SUCCESS\n",
      "  Rows: 10/10 successful\n",
      "  Batches: 1/1 successful\n",
      "  Tokens: 1,128 in / 2,026 out\n",
      "  Retries: 0 | Time: 9.01s\n",
      "======================================================================\n",
      "\n",
      "  [0] category='shipping' priority='urgent' requires_human=True suggested_response='Apologies for the damaged product. We will arrange for a replacement immediately. Please provide photos of the damage for our records.'\n",
      "  [1] category='billing' priority='low' requires_human=False suggested_response=\"You can change your subscription in your account settings under 'Billing & Plans'. Follow the steps to switch to annual billing.\"\n",
      "  [2] category='technical' priority='high' requires_human=True suggested_response='We apologize for the inconvenience. Please try these troubleshooting steps: [link to troubleshooting guide]. If the issue persists, we will escalate to our technical team.'\n",
      "  [3] category='billing' priority='high' requires_human=True suggested_response='We apologize for the double charge. We are investigating this issue and will process a refund for the duplicate charge immediately. You should see it reflected in your statement within 3-5 business days.'\n",
      "  [4] category='account' priority='medium' requires_human=False suggested_response=\"To set up two-factor authentication, go to your account security settings. You'll find step-by-step instructions there. Let us know if you encounter any issues.\"\n",
      "  [5] category='shipping' priority='urgent' requires_human=True suggested_response='We apologize for the damaged delivery. We are investigating this with the carrier and will arrange for a replacement or refund. Please provide photos of the damaged package and contents.'\n",
      "  [6] category='general' priority='medium' requires_human=False suggested_response=\"We're glad you like the product! An English version of the manual is available online at [link to manual]. Please let us know if you need further assistance.\"\n",
      "  [7] category='billing' priority='high' requires_human=True suggested_response=\"We're sorry to see you go. We can help you cancel your subscription and process a full refund for this month. Please confirm your account details.\"\n",
      "  [8] category='shipping' priority='high' requires_human=True suggested_response=\"We apologize if the item's color doesn't match the website. Please send us photos of the item you received. We can arrange a return or exchange.\"\n",
      "  [9] category='account' priority='high' requires_human=True suggested_response=\"To update your shipping address for future orders, please log into your account and navigate to 'My Addresses'. Make sure to save the new address. If your next order is shipping soon, please confirm your order number so we can try to update it manually.\"\n",
      "  ... and 7 more rows\n"
     ]
    }
   ],
   "source": [
    "model = Model(provider=\"google_genai\", name=\"gemini-2.5-flash\", api_key=GEMINI_KEY)\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Triage each support ticket with category, priority, escalation need, \"\n",
    "    \"and a suggested response.\",\n",
    "    output_model=TicketTriage,\n",
    "    batch_size=10,\n",
    "    stop_on_exhaustion=False,\n",
    ")\n",
    "\n",
    "result = await job.arun(model, data=tickets)\n",
    "show_result(\"Gemini / gemini-2.5-flash — Async Ticket Triage\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "All tests complete. Smelt successfully:\n",
    "- Transforms structured data through OpenAI, Anthropic, and Google Gemini\n",
    "- Returns strictly typed Pydantic models\n",
    "- Handles batching and concurrency\n",
    "- Provides detailed metrics (tokens, timing, retries)\n",
    "- Works in both sync (`job.run()`) and async (`await job.arun()`) modes\n",
    "\n",
    "> **Note:** Jupyter notebooks run inside an event loop, so all cells use `await job.arun()`.\n",
    "> Use `job.run()` in regular Python scripts where no event loop is running."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}