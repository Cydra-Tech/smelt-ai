{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Smelt AI — Live Demo\n",
    "\n",
    "Interactive walkthrough of smelt-ai across **OpenAI**, **Anthropic**, and **Google Gemini**.\n",
    "\n",
    "Tests:\n",
    "1. Basic classification (all 3 providers)\n",
    "2. Sentiment analysis with score validation\n",
    "3. Support ticket triage (complex schema)\n",
    "4. Parameter tuning (temperature, top_p)\n",
    "5. Batch configuration (batch_size, concurrency)\n",
    "6. Error handling (stop_on_exhaustion)\n",
    "7. Async execution\n",
    "8. 2026 generation models (GPT-5.2, Claude Sonnet 4.6, Opus 4.6, Gemini 3 Flash, Gemini 3 Pro)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Literal\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from smelt import Model, Job, SmeltResult, SmeltMetrics, BatchError\n",
    "from smelt.errors import SmeltExhaustionError\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "ANTHROPIC_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "GEMINI_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "print(f\"OpenAI key:    {'set' if OPENAI_KEY else 'MISSING'}\")\n",
    "print(f\"Anthropic key: {'set' if ANTHROPIC_KEY else 'MISSING'}\")\n",
    "print(f\"Gemini key:    {'set' if GEMINI_KEY else 'MISSING'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-header",
   "metadata": {},
   "source": [
    "## Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"../tests/data\")\n",
    "\n",
    "\n",
    "def load_csv(filename: str) -> list[dict[str, str]]:\n",
    "    \"\"\"Load CSV from tests/data directory.\"\"\"\n",
    "    with open(DATA_DIR / filename, newline=\"\", encoding=\"utf-8\") as f:\n",
    "        return list(csv.DictReader(f))\n",
    "\n",
    "\n",
    "companies = load_csv(\"companies.csv\")\n",
    "products = load_csv(\"products.csv\")\n",
    "tickets = load_csv(\"support_tickets.csv\")\n",
    "\n",
    "print(f\"Companies: {len(companies)} rows\")\n",
    "print(f\"Products:  {len(products)} rows\")\n",
    "print(f\"Tickets:   {len(tickets)} rows\")\n",
    "print()\n",
    "print(\"Sample company:\", companies[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "models-header",
   "metadata": {},
   "source": [
    "## Define Output Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "output-models",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndustryClassification(BaseModel):\n",
    "    \"\"\"Classification of a company by industry sector.\"\"\"\n",
    "    sector: str = Field(description=\"Primary industry sector\")\n",
    "    sub_sector: str = Field(description=\"More specific sub-sector\")\n",
    "    is_public: bool = Field(description=\"Whether the company is publicly traded\")\n",
    "\n",
    "\n",
    "class SentimentAnalysis(BaseModel):\n",
    "    \"\"\"Sentiment analysis of a product review.\"\"\"\n",
    "    sentiment: Literal[\"positive\", \"negative\", \"mixed\"] = Field(description=\"Overall sentiment\")\n",
    "    score: float = Field(description=\"Score from 0.0 (negative) to 1.0 (positive)\")\n",
    "    key_themes: list[str] = Field(description=\"Main themes in the review (1-3 items)\")\n",
    "\n",
    "\n",
    "class TicketTriage(BaseModel):\n",
    "    \"\"\"Support ticket triage result.\"\"\"\n",
    "    category: str = Field(description=\"Category: billing, technical, shipping, account, or general\")\n",
    "    priority: Literal[\"low\", \"medium\", \"high\", \"urgent\"] = Field(description=\"Priority level\")\n",
    "    requires_human: bool = Field(description=\"Whether human escalation is needed\")\n",
    "    suggested_response: str = Field(description=\"Brief suggested response to the customer\")\n",
    "\n",
    "\n",
    "class CompanySummary(BaseModel):\n",
    "    \"\"\"Structured company summary.\"\"\"\n",
    "    one_liner: str = Field(description=\"One sentence description\")\n",
    "    industry: str = Field(description=\"Primary industry\")\n",
    "    company_size: Literal[\"startup\", \"small\", \"medium\", \"large\", \"enterprise\"] = Field(\n",
    "        description=\"Size classification based on employee count\"\n",
    "    )\n",
    "    age_years: int = Field(description=\"Approximate age in years\")\n",
    "\n",
    "\n",
    "print(\"Output models defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helper-header",
   "metadata": {},
   "source": [
    "## Helper: Pretty-Print Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "helpers",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_result(label: str, result: SmeltResult) -> None:\n",
    "    \"\"\"Pretty-print a SmeltResult.\"\"\"\n",
    "    status = \"SUCCESS\" if result.success else \"FAILED\"\n",
    "    m = result.metrics\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"  {label}\")\n",
    "    print(f\"  Status: {status}\")\n",
    "    print(f\"  Rows: {m.successful_rows}/{m.total_rows} successful\")\n",
    "    print(f\"  Batches: {m.successful_batches}/{m.total_batches} successful\")\n",
    "    print(f\"  Tokens: {m.input_tokens:,} in / {m.output_tokens:,} out\")\n",
    "    print(f\"  Retries: {m.total_retries} | Time: {m.wall_time_seconds:.2f}s\")\n",
    "    if result.errors:\n",
    "        print(f\"  Errors: {len(result.errors)}\")\n",
    "        for e in result.errors:\n",
    "            print(f\"    - Batch {e.batch_index}: {e.error_type} ({e.attempts} attempts)\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print()\n",
    "    for i, row in enumerate(result.data):\n",
    "        print(f\"  [{i}] {row}\")\n",
    "    if len(result.data) > 3:\n",
    "        print(f\"  ... and {len(result.data) - 3} more rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test1-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Basic Classification — All 3 Providers\n",
    "\n",
    "Same task, same data, three different LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test1-openai",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI — GPT-4.1-mini\n",
    "model_openai = Model(provider=\"openai\", name=\"gpt-4.1-mini\", api_key=OPENAI_KEY)\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Classify each company by its primary industry sector and sub-sector. \"\n",
    "    \"Determine if the company is publicly traded.\",\n",
    "    output_model=IndustryClassification,\n",
    "    batch_size=10,\n",
    "    stop_on_exhaustion=False,\n",
    ")\n",
    "\n",
    "result = await job.arun(model_openai, data=companies)\n",
    "show_result(\"OpenAI / gpt-4.1-mini — Company Classification\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test1-anthropic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anthropic — Claude Sonnet 4\n",
    "model_anthropic = Model(provider=\"anthropic\", name=\"claude-sonnet-4-20250514\", api_key=ANTHROPIC_KEY)\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Classify each company by its primary industry sector and sub-sector. \"\n",
    "    \"Determine if the company is publicly traded.\",\n",
    "    output_model=IndustryClassification,\n",
    "    batch_size=10,\n",
    "    stop_on_exhaustion=False,\n",
    ")\n",
    "\n",
    "result = await job.arun(model_anthropic, data=companies)\n",
    "show_result(\"Anthropic / claude-sonnet-4 — Company Classification\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "test1-gemini",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Gemini — Gemini 2.5 Flash\n",
    "model_gemini = Model(provider=\"google_genai\", name=\"gemini-2.5-flash\", api_key=GEMINI_KEY)\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Classify each company by its primary industry sector and sub-sector. \"\n",
    "    \"Determine if the company is publicly traded.\",\n",
    "    output_model=IndustryClassification,\n",
    "    batch_size=10,\n",
    "    stop_on_exhaustion=False,\n",
    ")\n",
    "\n",
    "result = await job.arun(model_gemini, data=companies)\n",
    "show_result(\"Gemini / gemini-2.5-flash — Company Classification\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test2-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Sentiment Analysis — Score Validation\n",
    "\n",
    "Analyze product reviews and verify scores are in [0, 1] range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test2-openai",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(provider=\"openai\", name=\"gpt-4.1-mini\", api_key=OPENAI_KEY, params={\"temperature\": 0})\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Analyze the sentiment of each product's customer_review. \"\n",
    "    \"Identify the overall sentiment, assign a score between 0.0 and 1.0, \"\n",
    "    \"and extract 1-3 key themes.\",\n",
    "    output_model=SentimentAnalysis,\n",
    "    batch_size=5,\n",
    "    concurrency=2,\n",
    "    stop_on_exhaustion=False,\n",
    ")\n",
    "\n",
    "result = await job.arun(model, data=products)\n",
    "show_result(\"OpenAI / gpt-4.1-mini — Sentiment Analysis\", result)\n",
    "\n",
    "# Validate scores\n",
    "print(\"\\nScore validation:\")\n",
    "for i, row in enumerate(result.data):\n",
    "    in_range = 0.0 <= row.score <= 1.0\n",
    "    print(f\"  [{i}] score={row.score:.2f} sentiment={row.sentiment:8s} valid={in_range} themes={row.key_themes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test2-anthropic",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(provider=\"anthropic\", name=\"claude-haiku-4-5-20251001\", api_key=ANTHROPIC_KEY, params={\"temperature\": 0})\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Analyze the sentiment of each product's customer_review. \"\n",
    "    \"Identify the overall sentiment, assign a score between 0.0 and 1.0, \"\n",
    "    \"and extract 1-3 key themes.\",\n",
    "    output_model=SentimentAnalysis,\n",
    "    batch_size=5,\n",
    "    concurrency=2,\n",
    "    stop_on_exhaustion=False,\n",
    ")\n",
    "\n",
    "result = await job.arun(model, data=products)\n",
    "show_result(\"Anthropic / claude-haiku-4.5 — Sentiment Analysis\", result)\n",
    "\n",
    "print(\"\\nScore validation:\")\n",
    "for i, row in enumerate(result.data):\n",
    "    in_range = 0.0 <= row.score <= 1.0\n",
    "    print(f\"  [{i}] score={row.score:.2f} sentiment={row.sentiment:8s} valid={in_range} themes={row.key_themes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test2-gemini",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(provider=\"google_genai\", name=\"gemini-2.0-flash\", api_key=GEMINI_KEY, params={\"temperature\": 0})\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Analyze the sentiment of each product's customer_review. \"\n",
    "    \"Identify the overall sentiment, assign a score between 0.0 and 1.0, \"\n",
    "    \"and extract 1-3 key themes.\",\n",
    "    output_model=SentimentAnalysis,\n",
    "    batch_size=5,\n",
    "    concurrency=2,\n",
    "    stop_on_exhaustion=False,\n",
    ")\n",
    "\n",
    "result = await job.arun(model, data=products)\n",
    "show_result(\"Gemini / gemini-2.0-flash — Sentiment Analysis\", result)\n",
    "\n",
    "print(\"\\nScore validation:\")\n",
    "for i, row in enumerate(result.data):\n",
    "    in_range = 0.0 <= row.score <= 1.0\n",
    "    print(f\"  [{i}] score={row.score:.2f} sentiment={row.sentiment:8s} valid={in_range} themes={row.key_themes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test3-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Support Ticket Triage — Complex Schema\n",
    "\n",
    "Tests Literal types, booleans, and longer text generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test3-openai",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(provider=\"openai\", name=\"gpt-4.1-mini\", api_key=OPENAI_KEY)\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Triage each support ticket. Classify by category (billing, technical, \"\n",
    "    \"shipping, account, or general), assign priority, determine if human escalation \"\n",
    "    \"is needed, and write a brief suggested response.\",\n",
    "    output_model=TicketTriage,\n",
    "    batch_size=5,\n",
    "    concurrency=2,\n",
    "    stop_on_exhaustion=False,\n",
    ")\n",
    "\n",
    "result = await job.arun(model, data=tickets)\n",
    "show_result(\"OpenAI / gpt-4.1-mini — Ticket Triage\", result)\n",
    "\n",
    "print(\"\\nFull triage results:\")\n",
    "for i, row in enumerate(result.data):\n",
    "    print(f\"\\n  [{i}] {tickets[i]['ticket_id']}\")\n",
    "    print(f\"      Category: {row.category} | Priority: {row.priority} | Human: {row.requires_human}\")\n",
    "    print(f\"      Response: {row.suggested_response[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test3-anthropic",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(provider=\"anthropic\", name=\"claude-sonnet-4-20250514\", api_key=ANTHROPIC_KEY)\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Triage each support ticket. Classify by category (billing, technical, \"\n",
    "    \"shipping, account, or general), assign priority, determine if human escalation \"\n",
    "    \"is needed, and write a brief suggested response.\",\n",
    "    output_model=TicketTriage,\n",
    "    batch_size=5,\n",
    "    concurrency=2,\n",
    "    stop_on_exhaustion=False,\n",
    ")\n",
    "\n",
    "result = await job.arun(model, data=tickets)\n",
    "show_result(\"Anthropic / claude-sonnet-4 — Ticket Triage\", result)\n",
    "\n",
    "print(\"\\nFull triage results:\")\n",
    "for i, row in enumerate(result.data):\n",
    "    print(f\"\\n  [{i}] {tickets[i]['ticket_id']}\")\n",
    "    print(f\"      Category: {row.category} | Priority: {row.priority} | Human: {row.requires_human}\")\n",
    "    print(f\"      Response: {row.suggested_response[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test3-gemini",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(provider=\"google_genai\", name=\"gemini-2.5-flash\", api_key=GEMINI_KEY)\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Triage each support ticket. Classify by category (billing, technical, \"\n",
    "    \"shipping, account, or general), assign priority, determine if human escalation \"\n",
    "    \"is needed, and write a brief suggested response.\",\n",
    "    output_model=TicketTriage,\n",
    "    batch_size=5,\n",
    "    concurrency=2,\n",
    "    stop_on_exhaustion=False,\n",
    ")\n",
    "\n",
    "result = await job.arun(model, data=tickets)\n",
    "show_result(\"Gemini / gemini-2.5-flash — Ticket Triage\", result)\n",
    "\n",
    "print(\"\\nFull triage results:\")\n",
    "for i, row in enumerate(result.data):\n",
    "    print(f\"\\n  [{i}] {tickets[i]['ticket_id']}\")\n",
    "    print(f\"      Category: {row.category} | Priority: {row.priority} | Human: {row.requires_human}\")\n",
    "    print(f\"      Response: {row.suggested_response[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test4-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Parameter Tuning — Temperature Comparison\n",
    "\n",
    "Compare temperature=0 (deterministic) vs temperature=1.0 (creative) on the same task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test4-temp",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_subset = companies[:3]\n",
    "\n",
    "for temp in [0, 0.5, 1.0]:\n",
    "    model = Model(\n",
    "        provider=\"openai\", name=\"gpt-4.1-mini\", api_key=OPENAI_KEY,\n",
    "        params={\"temperature\": temp},\n",
    "    )\n",
    "    job = Job(\n",
    "        prompt=\"Classify each company by industry sector.\",\n",
    "        output_model=IndustryClassification,\n",
    "        batch_size=10,\n",
    "        stop_on_exhaustion=False,\n",
    "    )\n",
    "    result = await job.arun(model, data=data_subset)\n",
    "    show_result(f\"OpenAI / gpt-4.1-mini — temp={temp}\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test4-top-p",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anthropic: top_p (mutually exclusive with temperature) and top_k\n",
    "# NOTE: Anthropic does NOT allow setting both temperature and top_p simultaneously.\n",
    "for top_p in [0.5, 0.9]:\n",
    "    model = Model(\n",
    "        provider=\"anthropic\", name=\"claude-haiku-4-5-20251001\", api_key=ANTHROPIC_KEY,\n",
    "        params={\"top_p\": top_p, \"top_k\": 40},\n",
    "    )\n",
    "    job = Job(\n",
    "        prompt=\"Classify each company by industry sector.\",\n",
    "        output_model=IndustryClassification,\n",
    "        batch_size=10,\n",
    "        stop_on_exhaustion=False,\n",
    "    )\n",
    "    result = await job.arun(model, data=data_subset)\n",
    "    show_result(f\"Anthropic / claude-haiku-4.5 — top_p={top_p}, top_k=40\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test5-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Batch Configuration — Size & Concurrency\n",
    "\n",
    "Compare different batch_size and concurrency settings on the same dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test5-batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    {\"batch_size\": 10, \"concurrency\": 1, \"label\": \"1 batch, serial\"},\n",
    "    {\"batch_size\": 5, \"concurrency\": 2, \"label\": \"2 batches, conc=2\"},\n",
    "    {\"batch_size\": 2, \"concurrency\": 5, \"label\": \"5 batches, conc=5\"},\n",
    "    {\"batch_size\": 1, \"concurrency\": 10, \"label\": \"10 batches, conc=10\"},\n",
    "]\n",
    "\n",
    "model = Model(provider=\"openai\", name=\"gpt-4.1-mini\", api_key=OPENAI_KEY, params={\"temperature\": 0})\n",
    "\n",
    "for cfg in configs:\n",
    "    job = Job(\n",
    "        prompt=\"Classify each company by industry sector.\",\n",
    "        output_model=IndustryClassification,\n",
    "        batch_size=cfg[\"batch_size\"],\n",
    "        concurrency=cfg[\"concurrency\"],\n",
    "        stop_on_exhaustion=False,\n",
    "    )\n",
    "    result = await job.arun(model, data=companies)\n",
    "    show_result(f\"Config: {cfg['label']} (batch={cfg['batch_size']}, conc={cfg['concurrency']})\", result)\n",
    "    \n",
    "    # Verify all rows present and in order\n",
    "    assert len(result.data) == len(companies), f\"Row count mismatch: {len(result.data)} vs {len(companies)}\"\n",
    "    print(f\"  Row ordering verified: {len(result.data)} rows in correct order\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test6-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Error Handling — stop_on_exhaustion\n",
    "\n",
    "Demonstrate graceful error handling when `stop_on_exhaustion=False` collects errors,\n",
    "and when `stop_on_exhaustion=True` raises `SmeltExhaustionError` with partial results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test6-collect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_on_exhaustion=False: errors are collected, successful batches still returned\n",
    "model = Model(provider=\"openai\", name=\"gpt-4.1-mini\", api_key=OPENAI_KEY, params={\"temperature\": 0})\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Create a concise structured summary for each company. \"\n",
    "    \"Calculate age based on founded year (current year is 2026).\",\n",
    "    output_model=CompanySummary,\n",
    "    batch_size=5,\n",
    "    concurrency=2,\n",
    "    max_retries=2,\n",
    "    stop_on_exhaustion=False,  # collect errors, don't raise\n",
    ")\n",
    "\n",
    "result = await job.arun(model, data=companies)\n",
    "show_result(\"Company Summary (stop_on_exhaustion=False)\", result)\n",
    "\n",
    "print(f\"\\nsuccess property: {result.success}\")\n",
    "print(f\"result.data has {len(result.data)} rows\")\n",
    "print(f\"result.errors has {len(result.errors)} errors\")\n",
    "print(f\"result.metrics: {result.metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test6-exhaustion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_on_exhaustion=True with a valid request — should succeed without raising\n",
    "model = Model(provider=\"openai\", name=\"gpt-4.1-mini\", api_key=OPENAI_KEY, params={\"temperature\": 0})\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Classify each company by industry sector.\",\n",
    "    output_model=IndustryClassification,\n",
    "    batch_size=10,\n",
    "    max_retries=3,\n",
    "    stop_on_exhaustion=True,  # will raise on failure\n",
    ")\n",
    "\n",
    "try:\n",
    "    result = await job.arun(model, data=companies)\n",
    "    show_result(\"Classification (stop_on_exhaustion=True, no error expected)\", result)\n",
    "    print(\"No exception raised — all batches succeeded.\")\n",
    "except SmeltExhaustionError as e:\n",
    "    print(f\"SmeltExhaustionError: {e}\")\n",
    "    print(f\"Partial results: {len(e.partial_result.data)} rows succeeded\")\n",
    "    print(f\"Errors: {len(e.partial_result.errors)} batches failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test7-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Async Execution\n",
    "\n",
    "Use `await job.arun()` directly (works in Jupyter notebooks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test7-async-openai",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(provider=\"openai\", name=\"gpt-4.1-mini\", api_key=OPENAI_KEY, params={\"temperature\": 0})\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Classify each company by industry sector.\",\n",
    "    output_model=IndustryClassification,\n",
    "    batch_size=3,\n",
    "    concurrency=4,\n",
    "    stop_on_exhaustion=False,\n",
    ")\n",
    "\n",
    "result = await job.arun(model, data=companies)\n",
    "show_result(\"OpenAI / gpt-4.1-mini — Async (batch=3, conc=4)\", result)\n",
    "print(f\"  Batches: {result.metrics.total_batches} (ceil(10/3) = 4)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test7-async-anthropic",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(provider=\"anthropic\", name=\"claude-haiku-4-5-20251001\", api_key=ANTHROPIC_KEY)\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Analyze the sentiment of each product review.\",\n",
    "    output_model=SentimentAnalysis,\n",
    "    batch_size=5,\n",
    "    concurrency=2,\n",
    "    stop_on_exhaustion=False,\n",
    ")\n",
    "\n",
    "result = await job.arun(model, data=products)\n",
    "show_result(\"Anthropic / claude-haiku-4.5 — Async Sentiment\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test7-async-gemini",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(provider=\"google_genai\", name=\"gemini-2.5-flash\", api_key=GEMINI_KEY)\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Triage each support ticket with category, priority, escalation need, \"\n",
    "    \"and a suggested response.\",\n",
    "    output_model=TicketTriage,\n",
    "    batch_size=10,\n",
    "    stop_on_exhaustion=False,\n",
    ")\n",
    "\n",
    "result = await job.arun(model, data=tickets)\n",
    "show_result(\"Gemini / gemini-2.5-flash — Async Ticket Triage\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "All tests complete. Smelt successfully:\n",
    "- Transforms structured data through OpenAI, Anthropic, and Google Gemini\n",
    "- Returns strictly typed Pydantic models\n",
    "- Handles batching and concurrency\n",
    "- Provides detailed metrics (tokens, timing, retries)\n",
    "- Works in both sync (`job.run()`) and async (`await job.arun()`) modes\n",
    "- Tested with the latest 2026 generation models: GPT-5.2, Claude Sonnet 4.6, Claude Opus 4.6, Gemini 3 Flash, Gemini 3 Pro\n",
    "\n",
    "> **Note:** Jupyter notebooks run inside an event loop, so all cells use `await job.arun()`.\n",
    "> Use `job.run()` in regular Python scripts where no event loop is running."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889qqg82567",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. 2026 Generation Models\n",
    "\n",
    "Test the latest models from each provider: GPT-5.2, Claude Sonnet 4.6, Claude Opus 4.6, Gemini 3 Flash, Gemini 3 Pro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mvdyo2sd3qs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI — GPT-5.2\n",
    "model_gpt52 = Model(provider=\"openai\", name=\"gpt-5.2\", api_key=OPENAI_KEY)\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Classify each company by its primary industry sector and sub-sector. \"\n",
    "    \"Determine if the company is publicly traded.\",\n",
    "    output_model=IndustryClassification,\n",
    "    batch_size=10,\n",
    "    stop_on_exhaustion=False,\n",
    ")\n",
    "\n",
    "result = await job.arun(model_gpt52, data=companies)\n",
    "show_result(\"OpenAI / gpt-5.2 — Company Classification\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z59mw50bcq",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anthropic — Claude Sonnet 4.6\n",
    "model_sonnet46 = Model(provider=\"anthropic\", name=\"claude-sonnet-4-6\", api_key=ANTHROPIC_KEY)\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Classify each company by its primary industry sector and sub-sector. \"\n",
    "    \"Determine if the company is publicly traded.\",\n",
    "    output_model=IndustryClassification,\n",
    "    batch_size=5,\n",
    "    concurrency=2,\n",
    "    stop_on_exhaustion=False,\n",
    ")\n",
    "\n",
    "result = await job.arun(model_sonnet46, data=companies)\n",
    "show_result(\"Anthropic / claude-sonnet-4.6 — Company Classification\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tpvsy2953wr",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anthropic — Claude Opus 4.6\n",
    "model_opus46 = Model(provider=\"anthropic\", name=\"claude-opus-4-6\", api_key=ANTHROPIC_KEY)\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Triage each support ticket. Classify by category, assign priority, \"\n",
    "    \"determine if human escalation is needed, and suggest a brief response.\",\n",
    "    output_model=TicketTriage,\n",
    "    batch_size=10,\n",
    "    stop_on_exhaustion=False,\n",
    ")\n",
    "\n",
    "result = await job.arun(model_opus46, data=tickets[:5])\n",
    "show_result(\"Anthropic / claude-opus-4.6 — Ticket Triage (5 rows)\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6tb97ah1s",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google — Gemini 3 Flash\n",
    "model_gemini3 = Model(provider=\"google_genai\", name=\"gemini-3-flash-preview\", api_key=GEMINI_KEY)\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Analyze the sentiment of each product's customer_review. \"\n",
    "    \"Identify the overall sentiment, assign a score, and extract key themes.\",\n",
    "    output_model=SentimentAnalysis,\n",
    "    batch_size=5,\n",
    "    concurrency=2,\n",
    "    stop_on_exhaustion=False,\n",
    ")\n",
    "\n",
    "result = await job.arun(model_gemini3, data=products)\n",
    "show_result(\"Gemini / gemini-3-flash-preview — Sentiment Analysis\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rp9p6en5ege",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google — Gemini 3 Pro\n",
    "model_gemini3pro = Model(provider=\"google_genai\", name=\"gemini-3-pro-preview\", api_key=GEMINI_KEY)\n",
    "\n",
    "job = Job(\n",
    "    prompt=\"Classify each company by its primary industry sector and sub-sector. \"\n",
    "    \"Determine if the company is publicly traded.\",\n",
    "    output_model=IndustryClassification,\n",
    "    batch_size=10,\n",
    "    stop_on_exhaustion=False,\n",
    ")\n",
    "\n",
    "result = await job.arun(model_gemini3pro, data=companies[:5])\n",
    "show_result(\"Gemini / gemini-3-pro-preview — Company Classification (5 rows)\", result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
